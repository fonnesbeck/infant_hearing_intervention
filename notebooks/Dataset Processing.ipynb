{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and set options\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/clean/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database to import data for the three test domains and demographic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redcap import Project\n",
    "api_url = 'https://redcap.vanderbilt.edu/api/'\n",
    "api_key = open(\"/Users/fonnescj/Dropbox/Collaborations/LSL-DR/api_token.txt\").read()\n",
    "\n",
    "lsl_dr_project = Project(api_url, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = lsl_dr_project.export_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import each database from REDCap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation_fields = ['study_id','redcap_event_name', 'age_test_aaps','aaps_ss','age_test_gf2','gf2_ss', \n",
    "                       'gf3_siw_ss', 'gf3_sis_ss',' gf_version']\n",
    "# articulation_fields = ['study_id','redcap_event_name', 'age_test_aaps','aaps_ss','age_test_gf2','gf2_ss']\n",
    "articulation = lsl_dr_project.export_records(fields=articulation_fields, format='df', df_kwargs={'index_col':None,\n",
    "                                                                                                'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = lsl_dr_project.export_records(fields=articulation_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0101-2002-0101\n"
     ]
    }
   ],
   "source": [
    "print(records[0]['study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_fields = ['study_id','redcap_event_name','age_test_eowpvt','eowpvt_ss','age_test_evt',\n",
    "                     'evt_ss','evt_version']\n",
    "#expressive_fields = ['study_id','redcap_event_name','age_test_eowpvt','eowpvt_ss','age_test_evt','evt_ss']\n",
    "expressive = lsl_dr_project.export_records(fields=expressive_fields, format='df', \n",
    "                                           df_kwargs={'index_col':None,\n",
    "                                                      'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields = ['study_id','redcap_event_name','age_test_ppvt','ppvt_ss','ppvt_f','age_test_rowpvt','rowpvt_ss']\n",
    "#receptive_fields = ['study_id','redcap_event_name','age_test_ppvt','ppvt_ss','age_test_rowpvt','rowpvt_ss']\n",
    "receptive = lsl_dr_project.export_records(fields=receptive_fields, format='df', \n",
    "                                          df_kwargs={'index_col':None,\n",
    "                                                     'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_fields = ['study_id','redcap_event_name', 'test_sel3',\n",
    "                    'age_test_pls','pls_ac_ss','pls_ec_ss','pls_choice','pls_tl_ss',\n",
    "                    'age_test_owls','owls_lc_ss','owls_oe_ss','owls_oc_ss', 'owls_lcss',\n",
    "                    'age_test_celp', 'celfp_cl_ssss', 'celfp_rl_ss','celfp_el_ss',\n",
    "                    'age_test_celf', 'celf_cl', 'celf_rlss', 'celf_elss',\n",
    "                    'age_test_celf4', 'celf4_cl_ss', 'celf4_rl_ss', 'celf4_el_ss',\n",
    "                    'age_test_celf51', 'celf51_cl', 'celf51_rlss', 'celf51_elss',\n",
    "                    'age_test_celf52', 'celf52_cl', 'celf_rliss', 'celf52_eliss',\n",
    "                    'celfp_ss_ss', 'celfp_ws_ss', 'celfp_ev_ss', 'celfp_fd_ss',\n",
    "                    'celfp_rs_ss', 'celfp_bc_ss', 'celfp_wcr_ss', 'celfp_wce_ss',\n",
    "                    'celfp_wct_ss']\n",
    "\n",
    "# language_fields = ['study_id','redcap_event_name','pls_ac_ss','pls_ec_ss','pls_choice','age_test_pls',\n",
    "#                    'owls_lc_ss','owls_oe_ss','age_test_owls',\n",
    "#                    'celfp_rl_ss','celfp_el_ss','age_test_celp',\n",
    "#                    'celf_elss','celf_rlss','age_test_celf',\n",
    "#                    'celfp_ss_ss', 'celfp_ws_ss', 'celfp_ev_ss', 'celfp_fd_ss',\n",
    "#                    'celfp_rs_ss', 'celfp_bc_ss', 'celfp_wcr_ss', 'celfp_wce_ss',\n",
    "#                    'celfp_wct_ss']\n",
    "language_raw = lsl_dr_project.export_records(fields=language_fields, format='df', \n",
    "                                             df_kwargs={'index_col':None, \n",
    "                                                        'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## demographic_fields = ['study_id','redcap_event_name','redcap_data_access_group', 'academic_year_rv',\n",
    "# 'hl','prim_lang','mother_ed','father_ed','premature_age', 'synd_cause', 'age_disenrolled', 'race',\n",
    "# 'onset_1','age_int','age','age_amp', 'age_ci', 'age_ci_2', 'degree_hl_ad','type_hl_ad','tech_ad','degree_hl_as',\n",
    "# 'type_hl_as','tech_as','etiology','etiology_2', 'sib', 'gender', 'time', 'ad_250', 'as_250', 'ae',\n",
    "# 'ad_500', 'as_500', 'fam_age', 'family_inv', 'demo_ses', 'school_lunch', 'medicaid', 'hearing_changes',\n",
    "# 'slc_fo', 'sle_fo', 'a_fo', 'funct_out_age', 'parent_hl', 'med_cause', 'known_synd', 'school_grade',\n",
    "# 'att_days_hr', 'att_days_sch', 'att_days_st2_417', 'optionserv_type', 'option_pop', 'otherserv']\n",
    "\n",
    "demographic_fields = ['study_id','redcap_event_name','redcap_data_access_group', 'demo_ses', \n",
    "                      'academic_year_rv','hl','gender','race', 'sib', 'prim_lang','mother_ed',\n",
    "                      'father_ed','par1_ed','par2_ed', 'parent_hl', 'premature_age', 'onset_1',\n",
    "                      'age_int','age','age_amp', 'time', 'disenroll_status', 'newborn_screen_comp', \n",
    "                      'newborn_screen_ad', 'newborn_screen_as', 'age_disenrolled', 'med_cause', \n",
    "                      'synd_cause', 'known_synd', 'etiology','etiology_2', 'etiology_3', \n",
    "                      'etiology_oth', 'degree_hl_ad', \n",
    "                      'type_hl_ad', 'tech_ad', 'degree_hl_as', 'ae','type_hl_as','tech_as', \n",
    "                      'age_ci', 'age_ci_2', 'age_aod_ad', 'age_aod_as', 'ci_man_ad', 'ci_man_as',\n",
    "                      'ad_250', 'as_250', 'ad_500', 'as_500', 'ad_2000','as_2000','ad_4000',\n",
    "                      'as_4000', 'hearing_changes', 'school_grade', 'optionserv_type','option_kind_i', \n",
    "                      'option_kind_g', 'option_assess_type', 'option_pop', 'otherserv', 'other_kind_i', \n",
    "                      'other_kind_g', 'other_pop', 'slc_fo', 'sle_fo', 'a_fo', 'funct_out_age', \n",
    "                      'fam_age', 'family_inv', 'school_lunch', 'medicaid', 'demo_ses', 'att_type', \n",
    "                      'att_days_hr', 'att_days_sch', 'att_days_st2_417','freq_slp', 'int_slp', \n",
    "                      'fam_part', 'freq_deafed', 'int_deafed', 'fam_deafed']\n",
    "\n",
    "\n",
    "demographic_raw = lsl_dr_project.export_records(fields=demographic_fields, format='df', \n",
    "                                                df_kwargs={'index_col':None, \n",
    "                                                           'low_memory':False,\n",
    "                                                       'na_values':[888, 999, 9999]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attendance information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several fields in the demographic data have missing values. We can fill missing values forward from previous observation (by `study_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic = demographic_raw.sort_values(by='redcap_event_name').groupby('study_id').transform(\n",
    "                                    lambda recs: recs.fillna(method='ffill'))#.reset_index()\n",
    "demographic[\"study_id\"] = demographic_raw.sort_values(by='redcap_event_name').study_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random check to make sure this worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>par1_ed</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_deafed</th>\n",
       "      <th>int_deafed</th>\n",
       "      <th>fam_deafed</th>\n",
       "      <th>demo_ses</th>\n",
       "      <th>school_lunch</th>\n",
       "      <th>medicaid</th>\n",
       "      <th>newborn_screen_comp</th>\n",
       "      <th>newborn_screen_ad</th>\n",
       "      <th>newborn_screen_as</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18102</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18103</th>\n",
       "      <td>year_1_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18104</th>\n",
       "      <td>year_2_complete_71_arm_1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18105</th>\n",
       "      <td>year_3_complete_71_arm_1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              redcap_event_name  academic_year_rv   hl  gender  race  \\\n",
       "18102  initial_assessment_arm_1            2010.0  0.0     0.0   0.0   \n",
       "18103  year_1_complete_71_arm_1            2011.0  0.0     0.0   0.0   \n",
       "18104  year_2_complete_71_arm_1            2012.0  0.0     0.0   0.0   \n",
       "18105  year_3_complete_71_arm_1            2013.0  0.0     0.0   0.0   \n",
       "\n",
       "       prim_lang  sib  mother_ed  father_ed  par1_ed       ...        \\\n",
       "18102        0.0  1.0        3.0        3.0      NaN       ...         \n",
       "18103        0.0  1.0        3.0        3.0      NaN       ...         \n",
       "18104        0.0  1.0        3.0        3.0      NaN       ...         \n",
       "18105        0.0  1.0        3.0        3.0      NaN       ...         \n",
       "\n",
       "       freq_deafed  int_deafed  fam_deafed  demo_ses  school_lunch  medicaid  \\\n",
       "18102          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "18103          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "18104          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "18105          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "\n",
       "       newborn_screen_comp  newborn_screen_ad  newborn_screen_as  \\\n",
       "18102                  NaN                NaN                NaN   \n",
       "18103                  NaN                NaN                NaN   \n",
       "18104                  NaN                NaN                NaN   \n",
       "18105                  NaN                NaN                NaN   \n",
       "\n",
       "             study_id  \n",
       "18102  1147-2010-0064  \n",
       "18103  1147-2010-0064  \n",
       "18104  1147-2010-0064  \n",
       "18105  1147-2010-0064  \n",
       "\n",
       "[4 rows x 144 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic[demographic.study_id=='1147-2010-0064']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographic data without missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>par1_ed</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_deafed</th>\n",
       "      <th>int_deafed</th>\n",
       "      <th>fam_deafed</th>\n",
       "      <th>demo_ses</th>\n",
       "      <th>school_lunch</th>\n",
       "      <th>medicaid</th>\n",
       "      <th>newborn_screen_comp</th>\n",
       "      <th>newborn_screen_ad</th>\n",
       "      <th>newborn_screen_as</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101-2002-0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9661</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2004-0295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2004-1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9666</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2004-1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9672</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2004-1373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             redcap_event_name  academic_year_rv   hl  gender  race  \\\n",
       "0     initial_assessment_arm_1            2002.0  0.0     0.0   0.0   \n",
       "9661  initial_assessment_arm_1            2009.0  0.0     0.0   0.0   \n",
       "9664  initial_assessment_arm_1            2009.0  0.0     1.0   1.0   \n",
       "9666  initial_assessment_arm_1            2009.0  0.0     0.0   0.0   \n",
       "9672  initial_assessment_arm_1            2009.0  0.0     1.0   1.0   \n",
       "\n",
       "      prim_lang  sib  mother_ed  father_ed  par1_ed       ...        \\\n",
       "0           0.0  1.0        6.0        6.0      NaN       ...         \n",
       "9661        0.0  0.0        4.0        4.0      NaN       ...         \n",
       "9664        0.0  1.0        3.0        4.0      NaN       ...         \n",
       "9666        0.0  2.0        4.0        4.0      NaN       ...         \n",
       "9672        0.0  1.0        4.0        4.0      NaN       ...         \n",
       "\n",
       "      freq_deafed  int_deafed  fam_deafed  demo_ses  school_lunch  medicaid  \\\n",
       "0             NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "9661          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "9664          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "9666          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "9672          NaN         NaN         NaN       NaN           NaN       NaN   \n",
       "\n",
       "      newborn_screen_comp  newborn_screen_ad  newborn_screen_as  \\\n",
       "0                     NaN                NaN                NaN   \n",
       "9661                  NaN                NaN                NaN   \n",
       "9664                  NaN                NaN                NaN   \n",
       "9666                  NaN                NaN                NaN   \n",
       "9672                  NaN                NaN                NaN   \n",
       "\n",
       "            study_id  \n",
       "0     0101-2002-0101  \n",
       "9661  0628-2004-0295  \n",
       "9664  0628-2004-1305  \n",
       "9666  0628-2004-1312  \n",
       "9672  0628-2004-1373  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning languge dataset\n",
    "\n",
    "5 language measures:\n",
    "\n",
    "- 3 versions of CELF\n",
    "- PLS\n",
    "    - pls_ac_rs: \tPLS: Auditory Comprehension Raw Score\n",
    "    - pls_ac_ss: \tPLS: Auditory Comprehension Standard Score\n",
    "    - pls_ec_rs: \tPLS: Expressive Communication Raw Score\n",
    "    - pls_ec_ss: \tPLS: Expressive Communication Standard Score\n",
    "    - pls_tl_rs: \tPLS: Total Language Score Standard Score Total\n",
    "    - pls_tl_ss: \tPLS: Total Language Score Standard Score\n",
    "- OWLS\n",
    "    - age_test_owls: \tAge at time of testing (OWLS)\n",
    "    - owls_lc_rs: \tOWLS: Listening Comprehension Raw Score\n",
    "    - owls_lc_ss: \tOWLS: Listening Comprehension Standard Score\n",
    "    - owls_oe_rs: \tOWLS: Oral Expression Raw Score\n",
    "    - owls_oe_ss: \tOWLS: Oral Expression Standard Score\n",
    "    - owls_oc_sss: \tOWLS: Oral Composite Sum of Listening Comprehension and Oral Expression Standard Scores\n",
    "    - owls_oc_ss: \tOWLS: Oral Composite Standard Score\n",
    "    - owls_wes_trs: \tOWLS: Written Expression Scale Total Raw Score\n",
    "    - owls_wes_as: \tOWLS: Written Expression Scale Ability Score\n",
    "    - owls_wes_ss: \tOWLS: Written Expression Scale Standard Score\n",
    "    - owsl_lc: \tOWLS: Written Expression Scale Language Composite (Sum of written expression age-based standard score, listening comprehension standard score and oral expression standard score)\n",
    "    - owls_lcss: \tOWLS: Language Composite Standard Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_raw.columns.str.contains('celp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_type  expressive  receptive\n",
      "test_name                       \n",
      "CELF-4            685        585\n",
      "CELF-P2          2003       2008\n",
      "OWLS             1388       1394\n",
      "PLS              4648       4659\n",
      "There are 0 null values for score\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "language_raw[\"test_name\"] = None\n",
    "language_raw[\"test_type\"] = None\n",
    "language_raw[\"score\"] = None\n",
    "CELP = language_raw.age_test_celp.notnull()\n",
    "CELF = language_raw.age_test_celf.notnull()\n",
    "PLS = language_raw.age_test_pls.notnull()\n",
    "OWLS = language_raw.age_test_owls.notnull()\n",
    "\n",
    "language_raw['age_test'] = None\n",
    "language_raw.loc[CELP, 'age_test'] = language_raw.age_test_celp\n",
    "language_raw.loc[CELF, 'age_test'] = language_raw.age_test_celf\n",
    "language_raw.loc[PLS, 'age_test'] = language_raw.age_test_pls\n",
    "language_raw.loc[OWLS, 'age_test'] = language_raw.age_test_owls\n",
    "\n",
    "language1 = language_raw[CELP | CELF | PLS | OWLS].copy()\n",
    "language2 = language1.copy()\n",
    "\n",
    "language1[\"test_type\"] = \"receptive\"\n",
    "\n",
    "language1.loc[CELP, \"test_name\"] = \"CELF-P2\"\n",
    "language1.loc[CELF, \"test_name\"] = \"CELF-4\"\n",
    "language1.loc[PLS, \"test_name\"] = \"PLS\"\n",
    "language1.loc[OWLS, \"test_name\"] = \"OWLS\"\n",
    "\n",
    "language1.loc[CELP, \"score\"] = language1.celfp_rl_ss\n",
    "language1.loc[CELF, \"score\"] = language1.celf_rlss\n",
    "language1.loc[PLS, \"score\"] = language1.pls_ac_ss\n",
    "language1.loc[OWLS, \"score\"] = language1.owls_lc_ss\n",
    "\n",
    "\n",
    "language2[\"test_type\"] = \"expressive\"\n",
    "\n",
    "language2.loc[CELP, \"test_name\"] = \"CELF-P2\"\n",
    "language2.loc[CELF, \"test_name\"] = \"CELF-4\"\n",
    "language2.loc[PLS, \"test_name\"] = \"PLS\"\n",
    "language2.loc[OWLS, \"test_name\"] = \"OWLS\"\n",
    "\n",
    "language2.loc[CELP, \"score\"] = language1.celfp_el_ss\n",
    "language2.loc[CELF, \"score\"] = language1.celf_elss\n",
    "language2.loc[PLS, \"score\"] = language1.pls_ec_ss\n",
    "language2.loc[OWLS, \"score\"] = language1.owls_oe_ss\n",
    "\n",
    "language = pd.concat([language1, language2])\n",
    "language = language[language.score.notnull()]\n",
    "print(pd.crosstab(language.test_name, language.test_type))\n",
    "print(\"There are {0} null values for score\".format(sum(language[\"score\"].isnull())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "language[\"school\"] = language.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_subtest = language[[\"study_id\", \"redcap_event_name\", \"score\", \"test_type\", \n",
    "                             \"test_name\", \"school\", \"age_test\", \n",
    "                             'celfp_ss_ss', 'celfp_ws_ss', \n",
    "                             'celfp_ev_ss', 'celfp_fd_ss',\n",
    "                             'celfp_rs_ss', 'celfp_bc_ss', \n",
    "                             'celfp_wcr_ss', 'celfp_wce_ss',\n",
    "                             'celfp_wct_ss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = language[[\"study_id\", \"redcap_event_name\", \"score\", \"test_type\", \"test_name\", \"school\", \"age_test\"]]\n",
    "language[\"domain\"] = \"Language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "language.to_csv(DATA_DIR+'language.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning articulation dataset\n",
    "\n",
    "We converted the articulation dataset into a \"long\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goldman                 5896\n",
      "Arizonia                 568\n",
      "Arizonia and Goldman      94\n",
      "Name: test_type, dtype: int64\n",
      "There are 0 null values for test_type\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "articulation[\"test_type\"] = None\n",
    "ARIZ = articulation.aaps_ss.notnull()\n",
    "GF = articulation.gf2_ss.notnull()\n",
    "articulation = articulation[ARIZ | GF]\n",
    "articulation.loc[(ARIZ & GF), \"test_type\"] = \"Arizonia and Goldman\"\n",
    "articulation.loc[(ARIZ & ~GF), \"test_type\"] = \"Arizonia\"\n",
    "articulation.loc[(~ARIZ & GF), \"test_type\"] = \"Goldman\"\n",
    "\n",
    "print(articulation.test_type.value_counts())\n",
    "print(\"There are {0} null values for test_type\".format(sum(articulation[\"test_type\"].isnull())))\n",
    "\n",
    "# Test score (Arizonia if both)\n",
    "articulation[\"score\"] = articulation.aaps_ss\n",
    "articulation.loc[(~ARIZ & GF), \"score\"] = articulation.gf2_ss[~ARIZ & GF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation[\"school\"] = articulation.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age was taken to be the Arizonia age if there are both test types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6556.000000\n",
      "mean       67.846095\n",
      "std        29.681661\n",
      "min        23.000000\n",
      "25%        47.000000\n",
      "50%        60.000000\n",
      "75%        79.000000\n",
      "max       243.000000\n",
      "Name: age_test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "articulation[\"age_test\"] = articulation.age_test_aaps\n",
    "articulation.loc[articulation.age_test.isnull(), 'age_test'] = articulation.age_test_gf2[articulation.age_test.isnull()]\n",
    "print(articulation.age_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we dropped unwanted columns and added a domain identification column for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation[\"domain\"] = \"Articulation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation.to_csv(DATA_DIR+'articulation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning demographic dataset\n",
    "\n",
    "We excluded unwanted columns and rows for which age, gender or race were missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only subset of columns\n",
    "demographic = demographic.rename(columns={'gender':'male'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to sample size considerations, we reduced the non-English primary language variable to English (0) and non-English (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    14912\n",
      "True      3458\n",
      "Name: non_english, dtype: int64\n",
      "There are 523 null values for non_english\n"
     ]
    }
   ],
   "source": [
    "demographic[\"non_english\"] = None\n",
    "demographic.loc[demographic.prim_lang.notnull(), 'non_english'] = demographic.prim_lang[demographic.prim_lang.notnull()]>0\n",
    "print(demographic.non_english.value_counts())\n",
    "print(\"There are {0} null values for non_english\".format(sum(demographic.non_english.isnull())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mother's education (`mother_ed`) and father's education (`father_ed`) were both recoded to: \n",
    "\n",
    "* 0=no high school diploma\n",
    "* 1=high school\n",
    "* 2=undergraduate\n",
    "* 3=graduate\n",
    "\n",
    "Category 6 (unknown) was recoded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_mother_ed:\n",
      "6.0    6038\n",
      "4.0    4176\n",
      "3.0    2834\n",
      "5.0    2275\n",
      "2.0    2052\n",
      "1.0     609\n",
      "0.0     272\n",
      "Name: _mother_ed, dtype: int64\n",
      "mother_ed:\n",
      "1.0    4886\n",
      "2.0    4176\n",
      "3.0    2275\n",
      "0.0     881\n",
      "Name: mother_ed, dtype: int64\n",
      "\n",
      "There are 6675 null values for mother_ed\n"
     ]
    }
   ],
   "source": [
    "demographic = demographic.rename(columns={\"mother_ed\":\"_mother_ed\"})\n",
    "demographic[\"mother_ed\"] = demographic._mother_ed.copy()\n",
    "demographic.loc[demographic._mother_ed==1, 'mother_ed'] = 0\n",
    "demographic.loc[(demographic._mother_ed==2) | (demographic.mother_ed==3), 'mother_ed'] = 1\n",
    "demographic.loc[demographic._mother_ed==4, 'mother_ed'] = 2\n",
    "demographic.loc[demographic._mother_ed==5, 'mother_ed'] = 3\n",
    "demographic.loc[demographic._mother_ed==6, 'mother_ed'] = None\n",
    "print(\"_mother_ed:\")\n",
    "print(demographic._mother_ed.value_counts())\n",
    "print(\"mother_ed:\")\n",
    "print(demographic.mother_ed.value_counts())\n",
    "print(\"\\nThere are {0} null values for mother_ed\".format(sum(demographic.mother_ed.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_hl_lookup = {0: \"Both parents do not have a hearing loss\",\n",
    "        1: \"Both parents have hearing loss\",\n",
    "        2: \"Mother has hearing loss\",\n",
    "        3: \"Father has hearing loss\",\n",
    "        4: \"Unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['parent_hearing_loss'] = demographic.parent_hl.replace(parent_hl_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondary diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18893, 147)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['secondary_diagnosis'] = demographic.etiology==0\n",
    "# Suspected or unknown treated as missing\n",
    "demographic.loc[demographic.etiology > 1, 'secondary_diagnosis'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    13922\n",
       "1.0     2995\n",
       "Name: secondary_diagnosis, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.secondary_diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17704084648578353"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.secondary_diagnosis.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    7919\n",
       "0.0    3633\n",
       "2.0    1820\n",
       "1.0    1576\n",
       "3.0    1061\n",
       "Name: etiology_2, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.etiology_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2884"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.etiology_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.loc[demographic.etiology==3, 'etiology'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premature status was recoded to True (premature) and False (full-term). Here, premature indicates <36 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3529 null values for premature_weeks\n"
     ]
    }
   ],
   "source": [
    "demographic['premature_weeks'] = demographic.premature_age.copy()\n",
    "demographic.loc[demographic.premature_age==9, 'premature_weeks'] = None\n",
    "demographic.premature_weeks = abs(demographic.premature_weeks-8)*2\n",
    "print(\"There are {0} null values for premature_weeks\".format(sum(demographic.premature_weeks.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     13257\n",
       "2.0       770\n",
       "4.0       478\n",
       "12.0      238\n",
       "6.0       216\n",
       "10.0      197\n",
       "8.0       152\n",
       "14.0       51\n",
       "16.0        5\n",
       "Name: premature_weeks, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.premature_weeks.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode impant technology variables for each ear to one of four categories (None, Baha, Hearing aid, Cochlear implant):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     6595\n",
       "0.0     5544\n",
       "7.0     2084\n",
       "5.0     1302\n",
       "2.0      750\n",
       "6.0      510\n",
       "8.0      103\n",
       "9.0       88\n",
       "4.0       42\n",
       "3.0       27\n",
       "10.0      14\n",
       "Name: tech_ad, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.tech_ad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_cats = [\"None\", \"OAD\", \"Hearing aid\", \"Cochlear\", \"Other\"]\n",
    "\n",
    "demographic[\"tech_right\"] = 4\n",
    "demographic.loc[demographic.tech_ad==7, 'tech_right'] = 0\n",
    "demographic.loc[demographic.tech_ad==3, 'tech_right'] = 1\n",
    "demographic.loc[demographic.tech_ad.isin([1,2,4,5,10]), 'tech_right'] = 2\n",
    "demographic.loc[demographic.tech_ad.isin([0,8,6]), 'tech_right'] = 3\n",
    "demographic.loc[demographic.tech_ad.isnull(), 'tech_right'] = None\n",
    "\n",
    "demographic[\"tech_left\"] = 4\n",
    "demographic.loc[demographic.tech_as==7, 'tech_left'] = 0\n",
    "demographic.loc[demographic.tech_as==3, 'tech_left'] = 1\n",
    "demographic.loc[demographic.tech_as.isin([1,2,4,5,10]), 'tech_left'] = 2\n",
    "demographic.loc[demographic.tech_as.isin([0,8,6]), 'tech_left'] = 3\n",
    "demographic.loc[demographic.tech_as.isnull(), 'tech_left'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    8848\n",
       "3.0    5627\n",
       "0.0    2455\n",
       "4.0      69\n",
       "1.0      21\n",
       "Name: tech_left, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.tech_left.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    8703\n",
       "3.0    6157\n",
       "0.0    2084\n",
       "4.0      88\n",
       "1.0      27\n",
       "Name: tech_right, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.tech_right.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute valid missing values for hearing loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.loc[demographic.type_hl_ad==5, 'type_hl_ad'] = None\n",
    "demographic.loc[demographic.type_hl_as==5, 'type_hl_ad'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `degree_hl`, which is the maximum level of hearing loss in either ear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic[\"degree_hl\"] = np.maximum(demographic.degree_hl_ad, demographic.degree_hl_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create compound indicator variable for each technology (Baha, Hearing aid, Chochlear implant): \n",
    "\n",
    "* 0=none\n",
    "* 1=one ear\n",
    "* 2=both ears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oad:\n",
      "0.0    5952\n",
      "1.0       5\n",
      "2.0       1\n",
      "Name: oad, dtype: int64\n",
      "There are 1784 null values for OAD\n",
      "\n",
      "hearing_aid:\n",
      "2.0    2831\n",
      "0.0    2038\n",
      "1.0    1058\n",
      "Name: hearing_aid, dtype: int64\n",
      "There are 1834 null values for hearing_aid\n",
      "\n",
      "cochlear:\n",
      "0.0    4082\n",
      "2.0    1147\n",
      "1.0     729\n",
      "Name: cochlear, dtype: int64\n",
      "There are 1784 null values for cochlear\n",
      "18893\n"
     ]
    }
   ],
   "source": [
    "demographic[\"oad\"] = 0\n",
    "demographic.oad = demographic.oad.astype(object)\n",
    "demographic.loc[(demographic.tech_right==1) | (demographic.tech_left==1), 'oad'] = 1\n",
    "demographic.loc[(demographic.tech_right==1) & (demographic.tech_left==1), 'oad'] = 2\n",
    "demographic.loc[(demographic.tech_right.isnull()) & (demographic.tech_left.isnull()), 'oad'] = None\n",
    "print(\"oad:\")\n",
    "print(demographic.drop_duplicates(subset='study_id').oad.value_counts())\n",
    "print(\"There are {0} null values for OAD\".format(sum(demographic.oad.isnull())))\n",
    "\n",
    "demographic[\"hearing_aid\"] = 0\n",
    "demographic.hearing_aid = demographic.hearing_aid.astype(object)\n",
    "demographic.loc[(demographic.tech_right==2) | (demographic.tech_left==2), 'hearing_aid'] = 1\n",
    "demographic.loc[(demographic.tech_right==2) & (demographic.tech_left==2), 'hearing_aid'] = 2\n",
    "demographic.loc[(demographic.tech_right.isnull()) & (demographic.tech_right.isnull()), 'hearing_aid'] = None\n",
    "print(\"\\nhearing_aid:\")\n",
    "print(demographic.drop_duplicates(subset='study_id').hearing_aid.value_counts())\n",
    "print(\"There are {0} null values for hearing_aid\".format(sum(demographic.hearing_aid.isnull())))\n",
    "\n",
    "demographic[\"cochlear\"] = 0\n",
    "demographic.cochlear = demographic.cochlear.astype(object)\n",
    "demographic.loc[(demographic.tech_right==3) | (demographic.tech_left==3), 'cochlear'] = 1\n",
    "demographic.loc[(demographic.tech_right==3) & (demographic.tech_left==3), 'cochlear'] = 2\n",
    "demographic.loc[(demographic.tech_right.isnull()) & (demographic.tech_left.isnull()), 'cochlear'] = None\n",
    "print(\"\\ncochlear:\")\n",
    "print(demographic.drop_duplicates(subset='study_id').cochlear.value_counts())\n",
    "print(\"There are {0} null values for cochlear\".format(sum(demographic.cochlear.isnull())))\n",
    "print(len(demographic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify bilateral and bimodal individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic[\"unilateral_ci\"] = demographic.cochlear==1\n",
    "demographic[\"bilateral_ci\"] = demographic.cochlear==2\n",
    "demographic[\"unilateral_ha\"] = demographic.hearing_aid==1\n",
    "demographic[\"bilateral_ha\"] = demographic.hearing_aid==2\n",
    "demographic[\"bimodal\"] = (demographic.cochlear==1) & (demographic.hearing_aid==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4638, 7163, 1728, 2508)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.bilateral_ci.sum(), demographic.bilateral_ha.sum(), demographic.bimodal.sum(), demographic.unilateral_ci.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unilateral_ci     729\n",
       "bilateral_ci     1147\n",
       "bilateral_ha     2831\n",
       "bimodal           447\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.drop_duplicates(subset='study_id')[['unilateral_ci','bilateral_ci', \n",
    "                                               'bilateral_ha',\n",
    "                                               'bimodal']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variable that identifies bilateral (0), bilateral HA left (1), bilateral HA right (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values for tech\n"
     ]
    }
   ],
   "source": [
    "demographic['tech'] = 0\n",
    "demographic.loc[(demographic.bimodal) & (demographic.tech_left==2), 'tech'] = 1\n",
    "demographic.loc[(demographic.bimodal) & (demographic.tech_right==2), 'tech'] = 2\n",
    "print(\"There are {0} null values for tech\".format(sum(demographic.tech.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    7163\n",
       "3    4638\n",
       "4    1728\n",
       "1    1471\n",
       "0     760\n",
       "8      15\n",
       "2      11\n",
       "7       6\n",
       "5       1\n",
       "Name: implant_category, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic[\"implant_category\"] = None\n",
    "demographic.loc[(demographic.cochlear==1) & (demographic.hearing_aid==0) & (demographic.oad==0), \n",
    "                'implant_category'] = 0\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==1) & (demographic.oad==0), \n",
    "                'implant_category'] = 1\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==0) & (demographic.oad==1), \n",
    "                'implant_category'] = 2\n",
    "demographic.loc[(demographic.cochlear==2) & (demographic.hearing_aid==0) & (demographic.oad==0), \n",
    "                'implant_category'] = 3\n",
    "demographic.loc[(demographic.cochlear==1) & (demographic.hearing_aid==1) & (demographic.oad==0), \n",
    "                'implant_category'] = 4\n",
    "demographic.loc[(demographic.cochlear==1) & (demographic.hearing_aid==0) & (demographic.oad==1), \n",
    "                'implant_category'] = 5\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==2) & (demographic.oad==0), \n",
    "                'implant_category'] = 6\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==1) & (demographic.oad==1), \n",
    "                'implant_category'] = 7\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==0) & (demographic.oad==2), \n",
    "                'implant_category'] = 8\n",
    "demographic.implant_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age when hearing loss diagnosed** Data are entered inconsistently here, so we have to go in and replace non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need this anymore\n",
    "# demographic['age_diag'] = demographic.onset_1.replace({'birth': 0, 'R- Birth L-16mo': 0, 'birth - 3': 0, 'at birth': 0, 'NBHS': 0, \n",
    "#                              'at Birth': 0, '1-2': 1.5, '2-3': 2.5, '0-3': 1.5}).astype(float)\n",
    "demographic['age_diag'] = demographic.onset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of null values for `age_diag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.age_diag.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['sex'] = demographic.male.replace({0:'Female', 1:'Male'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Child has another diagnosed disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['known_synd'] = (demographic.synd_cause == 0)\n",
    "# Unknown or suspected\n",
    "demographic.loc[demographic.synd_cause > 1, 'known_synd'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If either known syndrome or secondary diagnosis\n",
    "demographic['synd_or_disab'] = (demographic.secondary_diagnosis.fillna(0).astype(bool) \n",
    "                                | demographic.known_synd.fillna(0).astype(bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing sibling counts were properly encoded as `None` (missing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.loc[demographic.sib==4, 'sib'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reduced the number of race categories, pooling those that were neither caucasian, black, hispanic or asian to \"other\", due to small sample sizes for these categories. Category 7 (unknown) was recoded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_race:\n",
      "0.0    9705\n",
      "2.0    3423\n",
      "1.0    1749\n",
      "3.0    1391\n",
      "6.0    1004\n",
      "8.0     647\n",
      "7.0     319\n",
      "4.0      76\n",
      "5.0      53\n",
      "Name: _race, dtype: int64\n",
      "race:\n",
      "0.0    9705\n",
      "2.0    3423\n",
      "4.0    1780\n",
      "1.0    1749\n",
      "3.0    1391\n",
      "Name: race, dtype: int64\n",
      "There are 845 null values for race\n"
     ]
    }
   ],
   "source": [
    "races = [\"Caucasian\", \"Black or African American\", \"Hispanic or Latino\", \"Asian\", \"Other\"]\n",
    "demographic = demographic.rename(columns={\"race\":\"_race\"})\n",
    "demographic[\"race\"] = demographic._race.copy()\n",
    "demographic.loc[demographic.race==7, 'race'] = None\n",
    "demographic.loc[demographic.race>3, 'race'] = 4\n",
    "print(\"_race:\")\n",
    "print(demographic._race.value_counts())\n",
    "print(\"race:\")\n",
    "print(demographic.race.value_counts())\n",
    "print(\"There are {0} null values for race\".format(sum(demographic.race.isnull())))\n",
    "# Replace with recoded column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode implant technology variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_cats = [\"None\", \"Baha\", \"Hearing aid\", \"Cochlear\", \"Other\"]\n",
    "\n",
    "demographic[\"tech_right\"] = demographic.tech_ad.copy()\n",
    "demographic.loc[demographic.tech_right==6, 'tech_right'] = 0\n",
    "demographic.loc[demographic.tech_right==4, 'tech_right'] = 1\n",
    "demographic.loc[demographic.tech_right==5, 'tech_right'] = 1\n",
    "demographic.loc[demographic.tech_right==3, 'tech_right'] = 2\n",
    "demographic.loc[demographic.tech_right==7, 'tech_right'] = 3\n",
    "demographic.loc[demographic.tech_right==8, 'tech_right'] = 3\n",
    "demographic.loc[demographic.tech_right==9, 'tech_right'] = 4\n",
    "demographic.tech_right = np.abs(demographic.tech_right - 3)\n",
    "\n",
    "demographic[\"tech_left\"] = demographic.tech_as.copy()\n",
    "demographic.loc[demographic.tech_left==6, 'tech_left'] = 0\n",
    "demographic.loc[demographic.tech_left==4, 'tech_left'] = 1\n",
    "demographic.loc[demographic.tech_left==5, 'tech_left'] = 1\n",
    "demographic.loc[demographic.tech_left==3, 'tech_left'] = 2\n",
    "demographic.loc[demographic.tech_left==7, 'tech_left'] = 3\n",
    "demographic.loc[demographic.tech_left==8, 'tech_left'] = 3\n",
    "demographic.loc[demographic.tech_left==9, 'tech_left'] = 4\n",
    "demographic.tech_left = np.abs(demographic.tech_left - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.to_csv(DATA_DIR+'demographics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning expressive vocabulary dataset\n",
    "\n",
    "We converted the expressive vocabulary dataset to \"long\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values for test_type\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "expressive[\"test_type\"] = None\n",
    "EOWPVT = expressive.eowpvt_ss.notnull()\n",
    "EVT = expressive.evt_ss.notnull()\n",
    "expressive = expressive[EOWPVT | EVT]\n",
    "expressive.loc[EOWPVT & EVT, \"test_type\"] = \"EOWPVT and EVT\"\n",
    "expressive.loc[EOWPVT & ~EVT, \"test_type\"] = \"EOWPVT\"\n",
    "expressive.loc[~EOWPVT & EVT, \"test_type\"] = \"EVT\"\n",
    "print(\"There are {0} null values for test_type\".format(sum(expressive[\"test_type\"].isnull())))\n",
    "\n",
    "expressive[\"score\"] = expressive.eowpvt_ss\n",
    "expressive.loc[~EOWPVT & EVT, \"score\"] = expressive.evt_ss[~EOWPVT & EVT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVT               4716\n",
       "EOWPVT            3382\n",
       "EOWPVT and EVT     212\n",
       "Name: test_type, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressive.test_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive[\"school\"] = expressive.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age was taken to be the EOWPVT age if there are both test types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive[\"age_test\"] = expressive.age_test_eowpvt\n",
    "expressive.loc[expressive.age_test.isnull(), 'age_test'] = expressive.age_test_evt[expressive.age_test.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we dropped unwanted columns and added a domain identification column for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive[\"domain\"] = \"Expressive Vocabulary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive.to_csv(DATA_DIR+'expressive_vocabulary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning receptive vocabulary dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the receptive vocabulary data table to \"long\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values for test_type\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "receptive[\"test_type\"] = None\n",
    "PPVT = receptive.ppvt_ss.notnull()\n",
    "ROWPVT = receptive.rowpvt_ss.notnull()\n",
    "receptive = receptive[PPVT | ROWPVT]\n",
    "receptive.loc[PPVT & ROWPVT, \"test_type\"] = \"PPVT and ROWPVT\"\n",
    "receptive.loc[PPVT & ~ROWPVT, \"test_type\"] = \"PPVT\"\n",
    "receptive.loc[~PPVT & ROWPVT, \"test_type\"] = \"ROWPVT\"\n",
    "print(\"There are {0} null values for test_type\".format(sum(receptive[\"test_type\"].isnull())))\n",
    "\n",
    "receptive[\"score\"] = receptive.ppvt_ss\n",
    "receptive.loc[~PPVT & ROWPVT, \"score\"] = receptive.rowpvt_ss[~PPVT & ROWPVT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive[\"school\"] = receptive.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age was taken to be the PPVT age if there are both test types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive[\"age_test\"] = receptive.age_test_ppvt\n",
    "receptive.loc[receptive.age_test.isnull(), 'age_test'] = receptive.age_test_rowpvt[receptive.age_test.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 null values for age_test\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {0} null values for age_test\".format(sum(receptive.age_test.isnull())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we dropped unwanted columns and added a domain identification column for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive[\"domain\"] = \"Receptive Vocabulary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3695,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive.study_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive.to_csv(DATA_DIR+'receptive_vocabulary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets\n",
    "\n",
    "The four datasets were mereged into a single table. First, we concatenate the test scores data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.concat([articulation, expressive, receptive, language])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform a merge between the demographic data and the test scores data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr = pd.merge(demographic, test_scores, on=[\"study_id\", \"redcap_event_name\"], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>male</th>\n",
       "      <th>_race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>_mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>par1_ed</th>\n",
       "      <th>...</th>\n",
       "      <th>gf3_sis_ss</th>\n",
       "      <th>gf3_siw_ss</th>\n",
       "      <th>gf_version</th>\n",
       "      <th>ppvt_f</th>\n",
       "      <th>ppvt_ss</th>\n",
       "      <th>rowpvt_ss</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>test_name</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40756</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40757</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40758</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0102</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Goldman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40759</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0102</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EOWPVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40760</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0102</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              redcap_event_name  academic_year_rv   hl  male  _race  \\\n",
       "40756  year_9_complete_71_arm_1            2011.0  0.0   0.0    0.0   \n",
       "40757  year_9_complete_71_arm_1            2011.0  0.0   0.0    0.0   \n",
       "40758  year_9_complete_71_arm_1            2015.0  0.0   0.0    0.0   \n",
       "40759  year_9_complete_71_arm_1            2015.0  0.0   0.0    0.0   \n",
       "40760  year_9_complete_71_arm_1            2015.0  0.0   0.0    0.0   \n",
       "\n",
       "       prim_lang  sib  _mother_ed  father_ed  par1_ed    ...      gf3_sis_ss  \\\n",
       "40756        0.0  1.0         6.0        6.0      NaN    ...             NaN   \n",
       "40757        0.0  1.0         6.0        6.0      NaN    ...             NaN   \n",
       "40758        0.0  0.0         2.0        6.0      NaN    ...             NaN   \n",
       "40759        0.0  0.0         2.0        6.0      NaN    ...             NaN   \n",
       "40760        0.0  0.0         2.0        6.0      NaN    ...             NaN   \n",
       "\n",
       "       gf3_siw_ss  gf_version  ppvt_f  ppvt_ss  rowpvt_ss  school  score  \\\n",
       "40756         NaN         NaN     NaN      NaN        NaN    1147     94   \n",
       "40757         NaN         NaN     1.0     90.0        NaN    1147     90   \n",
       "40758         NaN         2.0     NaN      NaN        NaN    0102     66   \n",
       "40759         NaN         NaN     NaN      NaN        NaN    0102     76   \n",
       "40760         NaN         NaN     0.0     65.0        NaN    0102     65   \n",
       "\n",
       "       test_name  test_type  \n",
       "40756        NaN        EVT  \n",
       "40757        NaN       PPVT  \n",
       "40758        NaN    Goldman  \n",
       "40759        NaN     EOWPVT  \n",
       "40760        NaN       PPVT  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsl_dr.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert score to floating-point number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr.score = lsl_dr.score.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr.to_csv(DATA_DIR+'lsl_dr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40761, 190)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsl_dr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
