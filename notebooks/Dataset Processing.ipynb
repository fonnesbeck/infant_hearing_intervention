{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and set options\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/clean/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database to import data for the three test domains and demographic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redcap import Project\n",
    "api_url = 'https://redcap.vanderbilt.edu/api/'\n",
    "api_key = open(\"/Users/fonnescj/Dropbox/Collaborations/LSL-DR/api_token.txt\").read()\n",
    "\n",
    "lsl_dr_project = Project(api_url, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = lsl_dr_project.export_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import each database from REDCap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation_fields = ['study_id','redcap_event_name', 'age_test_aaps','aaps_ss','age_test_gf2','gf2_ss']\n",
    "articulation = lsl_dr_project.export_records(fields=articulation_fields, format='df', df_kwargs={'index_col':None,\n",
    "                                                                                                'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = lsl_dr_project.export_records(fields=articulation_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0101-2002-0101\n"
     ]
    }
   ],
   "source": [
    "print(records[0]['study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_fields = ['study_id','redcap_event_name','age_test_eowpvt','eowpvt_ss','age_test_evt','evt_ss']\n",
    "expressive = lsl_dr_project.export_records(fields=expressive_fields, format='df', \n",
    "                                           df_kwargs={'index_col':None,\n",
    "                                                      'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields = ['study_id','redcap_event_name','age_test_ppvt','ppvt_ss','age_test_rowpvt','rowpvt_ss']\n",
    "receptive = lsl_dr_project.export_records(fields=receptive_fields, format='df', \n",
    "                                          df_kwargs={'index_col':None,\n",
    "                                                     'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_fields = ['study_id','redcap_event_name','pls_ac_ss','pls_ec_ss','pls_choice','age_test_pls',\n",
    "                   'owls_lc_ss','owls_oe_ss','age_test_owls',\n",
    "                   'celfp_rl_ss','celfp_el_ss','age_test_celp',\n",
    "                   'celf_elss','celf_rlss','age_test_celf',\n",
    "                   'celfp_ss_ss', 'celfp_ws_ss', 'celfp_ev_ss', 'celfp_fd_ss',\n",
    "                   'celfp_rs_ss', 'celfp_bc_ss', 'celfp_wcr_ss', 'celfp_wce_ss',\n",
    "                   'celfp_wct_ss']\n",
    "language_raw = lsl_dr_project.export_records(fields=language_fields, format='df', \n",
    "                                             df_kwargs={'index_col':None, \n",
    "                                                        'na_values':[999, 9999]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fonnescj/anaconda3/envs/early_intervention/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (27,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "demographic_fields = ['study_id','redcap_event_name','redcap_data_access_group', 'academic_year_rv',\n",
    "'hl','prim_lang','mother_ed','father_ed','premature_age', 'synd_cause', 'age_disenrolled', 'race',\n",
    "'onset_1','age_int','age','age_amp', 'age_ci', 'age_ci_2', 'degree_hl_ad','type_hl_ad','tech_ad','degree_hl_as',\n",
    "'type_hl_as','tech_as','etiology','etiology_2', 'sib', 'gender', 'time', 'ad_250', 'as_250', 'ae',\n",
    "'ad_500', 'as_500', 'fam_age', 'family_inv', 'demo_ses', 'school_lunch', 'medicaid', 'hearing_changes',\n",
    "'slc_fo', 'sle_fo', 'a_fo', 'funct_out_age', 'parent_hl', 'med_cause', 'known_synd', 'school_grade',\n",
    "'att_days_hr', 'att_days_sch', 'att_days_st2_417', 'optionserv_type', 'option_pop', 'otherserv']\n",
    "demographic_raw = lsl_dr_project.export_records(fields=demographic_fields, format='df', \n",
    "                                            df_kwargs={'index_col':None, \n",
    "                                                       'na_values':[888, 999, 9999]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attendance information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several fields in the demographic data have missing values. We can fill missing values forward from previous observation (by `study_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic = demographic_raw.sort_values(by='redcap_event_name').groupby('study_id').transform(\n",
    "                                    lambda recs: recs.fillna(method='ffill'))#.reset_index()\n",
    "demographic[\"study_id\"] = demographic_raw.sort_values(by='redcap_event_name').study_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random check to make sure this worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>parent_hl</th>\n",
       "      <th>...</th>\n",
       "      <th>a_fo</th>\n",
       "      <th>fam_age</th>\n",
       "      <th>family_inv</th>\n",
       "      <th>att_days_sch</th>\n",
       "      <th>att_days_st2_417</th>\n",
       "      <th>att_days_hr</th>\n",
       "      <th>demo_ses</th>\n",
       "      <th>school_lunch</th>\n",
       "      <th>medicaid</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18009</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18010</th>\n",
       "      <td>year_1_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18011</th>\n",
       "      <td>year_2_complete_71_arm_1</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18012</th>\n",
       "      <td>year_3_complete_71_arm_1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147-2010-0064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              redcap_event_name  academic_year_rv   hl  gender  race  \\\n",
       "18009  initial_assessment_arm_1            2010.0  0.0     0.0   0.0   \n",
       "18010  year_1_complete_71_arm_1            2011.0  0.0     0.0   0.0   \n",
       "18011  year_2_complete_71_arm_1            2012.0  0.0     0.0   0.0   \n",
       "18012  year_3_complete_71_arm_1            2013.0  0.0     0.0   0.0   \n",
       "\n",
       "       prim_lang  sib  mother_ed  father_ed  parent_hl       ...        a_fo  \\\n",
       "18009        0.0  1.0        3.0        3.0        NaN       ...         6.0   \n",
       "18010        0.0  1.0        3.0        3.0        NaN       ...         5.0   \n",
       "18011        0.0  1.0        3.0        3.0        NaN       ...         5.0   \n",
       "18012        0.0  1.0        3.0        3.0        NaN       ...         5.0   \n",
       "\n",
       "       fam_age  family_inv  att_days_sch  att_days_st2_417  att_days_hr  \\\n",
       "18009     65.0         0.0           NaN               NaN          NaN   \n",
       "18010     77.0         2.0           NaN               NaN          NaN   \n",
       "18011     89.0         2.0           NaN               NaN          NaN   \n",
       "18012    101.0         2.0           NaN               NaN          NaN   \n",
       "\n",
       "       demo_ses  school_lunch  medicaid        study_id  \n",
       "18009       NaN           NaN       NaN  1147-2010-0064  \n",
       "18010       NaN           NaN       NaN  1147-2010-0064  \n",
       "18011       NaN           NaN       NaN  1147-2010-0064  \n",
       "18012       NaN           NaN       NaN  1147-2010-0064  \n",
       "\n",
       "[4 rows x 56 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic[demographic.study_id=='1147-2010-0064']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographic data without missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>parent_hl</th>\n",
       "      <th>...</th>\n",
       "      <th>a_fo</th>\n",
       "      <th>fam_age</th>\n",
       "      <th>family_inv</th>\n",
       "      <th>att_days_sch</th>\n",
       "      <th>att_days_st2_417</th>\n",
       "      <th>att_days_hr</th>\n",
       "      <th>demo_ses</th>\n",
       "      <th>school_lunch</th>\n",
       "      <th>medicaid</th>\n",
       "      <th>study_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0101-2002-0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2003-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2003-1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2003-1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9614</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0628-2003-1275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             redcap_event_name  academic_year_rv   hl  gender  race  \\\n",
       "0     initial_assessment_arm_1            2002.0  0.0     0.0   0.0   \n",
       "9599  initial_assessment_arm_1            2009.0  0.0     1.0   0.0   \n",
       "9601  initial_assessment_arm_1            2009.0  0.0     1.0   0.0   \n",
       "9606  initial_assessment_arm_1            2009.0  0.0     0.0   2.0   \n",
       "9614  initial_assessment_arm_1            2009.0  0.0     0.0   2.0   \n",
       "\n",
       "      prim_lang  sib  mother_ed  father_ed  parent_hl       ...        a_fo  \\\n",
       "0           0.0  1.0        6.0        6.0        0.0       ...         2.0   \n",
       "9599        0.0  0.0        6.0        6.0        0.0       ...         5.0   \n",
       "9601        0.0  1.0        5.0        3.0        0.0       ...         4.0   \n",
       "9606        0.0  4.0        6.0        6.0        0.0       ...         4.0   \n",
       "9614        6.0  3.0        3.0        2.0        0.0       ...         4.0   \n",
       "\n",
       "      fam_age  family_inv  att_days_sch  att_days_st2_417  att_days_hr  \\\n",
       "0        54.0         2.0           NaN               NaN          NaN   \n",
       "9599    108.0         1.0           NaN               NaN          NaN   \n",
       "9601    104.0         0.0           NaN               NaN          NaN   \n",
       "9606    115.0         1.0           NaN               NaN          NaN   \n",
       "9614     87.0         2.0           NaN               NaN          NaN   \n",
       "\n",
       "      demo_ses  school_lunch  medicaid        study_id  \n",
       "0          NaN           NaN       NaN  0101-2002-0101  \n",
       "9599       NaN           NaN       NaN  0628-2003-1000  \n",
       "9601       NaN           NaN       NaN  0628-2003-1124  \n",
       "9606       NaN           NaN       NaN  0628-2003-1174  \n",
       "9614       NaN           NaN       NaN  0628-2003-1275  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning languge dataset\n",
    "\n",
    "5 language measures:\n",
    "\n",
    "- 3 versions of CELF\n",
    "- PLS\n",
    "    - pls_ac_rs: \tPLS: Auditory Comprehension Raw Score\n",
    "    - pls_ac_ss: \tPLS: Auditory Comprehension Standard Score\n",
    "    - pls_ec_rs: \tPLS: Expressive Communication Raw Score\n",
    "    - pls_ec_ss: \tPLS: Expressive Communication Standard Score\n",
    "    - pls_tl_rs: \tPLS: Total Language Score Standard Score Total\n",
    "    - pls_tl_ss: \tPLS: Total Language Score Standard Score\n",
    "- OWLS\n",
    "    - age_test_owls: \tAge at time of testing (OWLS)\n",
    "    - owls_lc_rs: \tOWLS: Listening Comprehension Raw Score\n",
    "    - owls_lc_ss: \tOWLS: Listening Comprehension Standard Score\n",
    "    - owls_oe_rs: \tOWLS: Oral Expression Raw Score\n",
    "    - owls_oe_ss: \tOWLS: Oral Expression Standard Score\n",
    "    - owls_oc_sss: \tOWLS: Oral Composite Sum of Listening Comprehension and Oral Expression Standard Scores\n",
    "    - owls_oc_ss: \tOWLS: Oral Composite Standard Score\n",
    "    - owls_wes_trs: \tOWLS: Written Expression Scale Total Raw Score\n",
    "    - owls_wes_as: \tOWLS: Written Expression Scale Ability Score\n",
    "    - owls_wes_ss: \tOWLS: Written Expression Scale Standard Score\n",
    "    - owsl_lc: \tOWLS: Written Expression Scale Language Composite (Sum of written expression age-based standard score, listening comprehension standard score and oral expression standard score)\n",
    "    - owls_lcss: \tOWLS: Language Composite Standard Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_type  expressive  receptive\n",
      "test_name                       \n",
      "CELF-4            685        585\n",
      "CELF-P2          1979       1983\n",
      "OWLS             1382       1388\n",
      "PLS              4641       4652\n",
      "There are 0 null values for score\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "language_raw[\"test_name\"] = None\n",
    "language_raw[\"test_type\"] = None\n",
    "language_raw[\"score\"] = None\n",
    "CELP = language_raw.age_test_celp.notnull()\n",
    "CELF = language_raw.age_test_celf.notnull()\n",
    "PLS = language_raw.age_test_pls.notnull()\n",
    "OWLS = language_raw.age_test_owls.notnull()\n",
    "\n",
    "language_raw['age_test'] = None\n",
    "language_raw.loc[CELP, 'age_test'] = language_raw.age_test_celp\n",
    "language_raw.loc[CELF, 'age_test'] = language_raw.age_test_celf\n",
    "language_raw.loc[PLS, 'age_test'] = language_raw.age_test_pls\n",
    "language_raw.loc[OWLS, 'age_test'] = language_raw.age_test_owls\n",
    "\n",
    "language1 = language_raw[CELP | CELF | PLS | OWLS].copy()\n",
    "language2 = language1.copy()\n",
    "\n",
    "language1[\"test_type\"] = \"receptive\"\n",
    "\n",
    "language1.loc[CELP, \"test_name\"] = \"CELF-P2\"\n",
    "language1.loc[CELF, \"test_name\"] = \"CELF-4\"\n",
    "language1.loc[PLS, \"test_name\"] = \"PLS\"\n",
    "language1.loc[OWLS, \"test_name\"] = \"OWLS\"\n",
    "\n",
    "language1.loc[CELP, \"score\"] = language1.celfp_rl_ss\n",
    "language1.loc[CELF, \"score\"] = language1.celf_rlss\n",
    "language1.loc[PLS, \"score\"] = language1.pls_ac_ss\n",
    "language1.loc[OWLS, \"score\"] = language1.owls_lc_ss\n",
    "\n",
    "\n",
    "language2[\"test_type\"] = \"expressive\"\n",
    "\n",
    "language2.loc[CELP, \"test_name\"] = \"CELF-P2\"\n",
    "language2.loc[CELF, \"test_name\"] = \"CELF-4\"\n",
    "language2.loc[PLS, \"test_name\"] = \"PLS\"\n",
    "language2.loc[OWLS, \"test_name\"] = \"OWLS\"\n",
    "\n",
    "language2.loc[CELP, \"score\"] = language1.celfp_el_ss\n",
    "language2.loc[CELF, \"score\"] = language1.celf_elss\n",
    "language2.loc[PLS, \"score\"] = language1.pls_ec_ss\n",
    "language2.loc[OWLS, \"score\"] = language1.owls_oe_ss\n",
    "\n",
    "language = pd.concat([language1, language2])\n",
    "language = language[language.score.notnull()]\n",
    "print(pd.crosstab(language.test_name, language.test_type))\n",
    "print(\"There are {0} null values for score\".format(sum(language[\"score\"].isnull())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "language[\"school\"] = language.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_subtest = language[[\"study_id\", \"redcap_event_name\", \"score\", \"test_type\", \n",
    "                             \"test_name\", \"school\", \"age_test\", \n",
    "                             'celfp_ss_ss', 'celfp_ws_ss', \n",
    "                             'celfp_ev_ss', 'celfp_fd_ss',\n",
    "                             'celfp_rs_ss', 'celfp_bc_ss', \n",
    "                             'celfp_wcr_ss', 'celfp_wce_ss',\n",
    "                             'celfp_wct_ss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = language[[\"study_id\", \"redcap_event_name\", \"score\", \"test_type\", \"test_name\", \"school\", \"age_test\"]]\n",
    "language[\"domain\"] = \"Language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "language.to_csv(DATA_DIR+'language.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning articulation dataset\n",
    "\n",
    "We converted the articulation dataset into a \"long\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goldman                 5882\n",
      "Arizonia                 568\n",
      "Arizonia and Goldman      94\n",
      "Name: test_type, dtype: int64\n",
      "There are 0 null values for test_type\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "articulation[\"test_type\"] = None\n",
    "ARIZ = articulation.aaps_ss.notnull()\n",
    "GF = articulation.gf2_ss.notnull()\n",
    "articulation = articulation[ARIZ | GF]\n",
    "articulation.loc[(ARIZ & GF), \"test_type\"] = \"Arizonia and Goldman\"\n",
    "articulation.loc[(ARIZ & ~GF), \"test_type\"] = \"Arizonia\"\n",
    "articulation.loc[(~ARIZ & GF), \"test_type\"] = \"Goldman\"\n",
    "\n",
    "print(articulation.test_type.value_counts())\n",
    "print(\"There are {0} null values for test_type\".format(sum(articulation[\"test_type\"].isnull())))\n",
    "\n",
    "# Test score (Arizonia if both)\n",
    "articulation[\"score\"] = articulation.aaps_ss\n",
    "articulation.loc[(~ARIZ & GF), \"score\"] = articulation.gf2_ss[~ARIZ & GF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation[\"school\"] = articulation.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age was taken to be the Arizonia age if there are both test types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6542.000000\n",
      "mean       67.900948\n",
      "std        29.689799\n",
      "min        23.000000\n",
      "25%        47.000000\n",
      "50%        60.000000\n",
      "75%        80.000000\n",
      "max       243.000000\n",
      "Name: age_test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "articulation[\"age_test\"] = articulation.age_test_aaps\n",
    "articulation.loc[articulation.age_test.isnull(), 'age_test'] = articulation.age_test_gf2[articulation.age_test.isnull()]\n",
    "print(articulation.age_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we dropped unwanted columns and added a domain identification column for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation[\"domain\"] = \"Articulation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation.to_csv(DATA_DIR+'articulation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning demographic dataset\n",
    "\n",
    "We excluded unwanted columns and rows for which age, gender or race were missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only subset of columns\n",
    "demographic = demographic.rename(columns={'gender':'male'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to sample size considerations, we reduced the non-English primary language variable to English (0) and non-English (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    14838\n",
      "True      3453\n",
      "Name: non_english, dtype: int64\n",
      "There are 509 null values for non_english\n"
     ]
    }
   ],
   "source": [
    "demographic[\"non_english\"] = None\n",
    "demographic.loc[demographic.prim_lang.notnull(), 'non_english'] = demographic.prim_lang[demographic.prim_lang.notnull()]>0\n",
    "print(demographic.non_english.value_counts())\n",
    "print(\"There are {0} null values for non_english\".format(sum(demographic.non_english.isnull())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mother's education (`mother_ed`) and father's education (`father_ed`) were both recoded to: \n",
    "\n",
    "* 0=no high school diploma\n",
    "* 1=high school\n",
    "* 2=undergraduate\n",
    "* 3=graduate\n",
    "\n",
    "Category 6 (unknown) was recoded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_mother_ed:\n",
      "6.0    6034\n",
      "4.0    4151\n",
      "3.0    2814\n",
      "5.0    2260\n",
      "2.0    2035\n",
      "1.0     607\n",
      "0.0     271\n",
      "Name: _mother_ed, dtype: int64\n",
      "mother_ed:\n",
      "1.0    4849\n",
      "2.0    4151\n",
      "3.0    2260\n",
      "0.0     878\n",
      "Name: mother_ed, dtype: int64\n",
      "\n",
      "There are 6662 null values for mother_ed\n"
     ]
    }
   ],
   "source": [
    "demographic = demographic.rename(columns={\"mother_ed\":\"_mother_ed\"})\n",
    "demographic[\"mother_ed\"] = demographic._mother_ed.copy()\n",
    "demographic.loc[demographic._mother_ed==1, 'mother_ed'] = 0\n",
    "demographic.loc[(demographic._mother_ed==2) | (demographic.mother_ed==3), 'mother_ed'] = 1\n",
    "demographic.loc[demographic._mother_ed==4, 'mother_ed'] = 2\n",
    "demographic.loc[demographic._mother_ed==5, 'mother_ed'] = 3\n",
    "demographic.loc[demographic._mother_ed==6, 'mother_ed'] = None\n",
    "print(\"_mother_ed:\")\n",
    "print(demographic._mother_ed.value_counts())\n",
    "print(\"mother_ed:\")\n",
    "print(demographic.mother_ed.value_counts())\n",
    "print(\"\\nThere are {0} null values for mother_ed\".format(sum(demographic.mother_ed.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_hl_lookup = {0: \"Both parents do not have a hearing loss\",\n",
    "        1: \"Both parents have hearing loss\",\n",
    "        2: \"Mother has hearing loss\",\n",
    "        3: \"Father has hearing loss\",\n",
    "        4: \"Unknown\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['parent_hearing_loss'] = demographic.parent_hl.replace(parent_hl_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondary diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18800, 59)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['secondary_diagnosis'] = demographic.etiology==0\n",
    "# Suspected or unknown treated as missing\n",
    "demographic.loc[demographic.etiology > 1, 'secondary_diagnosis'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    13846\n",
       "1.0     2984\n",
       "Name: secondary_diagnosis, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.secondary_diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17730243612596555"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.secondary_diagnosis.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premature status was recoded to True (premature) and False (full-term). Here, premature indicates <36 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3519 null values for premature_weeks\n"
     ]
    }
   ],
   "source": [
    "demographic['premature_weeks'] = demographic.premature_age.copy()\n",
    "demographic.loc[demographic.premature_age==9, 'premature_weeks'] = None\n",
    "demographic.premature_weeks = abs(demographic.premature_weeks-8)*2\n",
    "print(\"There are {0} null values for premature_weeks\".format(sum(demographic.premature_weeks.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     13191\n",
       "2.0       768\n",
       "4.0       474\n",
       "12.0      235\n",
       "6.0       212\n",
       "10.0      197\n",
       "8.0       150\n",
       "14.0       49\n",
       "16.0        5\n",
       "Name: premature_weeks, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.premature_weeks.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode impant technology variables for each ear to one of four categories (None, Baha, Hearing aid, Cochlear implant):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     6559\n",
       "0.0     5519\n",
       "7.0     2076\n",
       "5.0     1300\n",
       "2.0      748\n",
       "6.0      510\n",
       "8.0      103\n",
       "9.0       88\n",
       "4.0       42\n",
       "3.0       27\n",
       "10.0      14\n",
       "Name: tech_ad, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.tech_ad.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_cats = [\"None\", \"OAD\", \"Hearing aid\", \"Cochlear\", \"Other\"]\n",
    "\n",
    "demographic[\"tech_right\"] = 4\n",
    "demographic.loc[demographic.tech_ad==7, 'tech_right'] = 0\n",
    "demographic.loc[demographic.tech_ad==3, 'tech_right'] = 1\n",
    "demographic.loc[demographic.tech_ad.isin([1,2,4,5,10]), 'tech_right'] = 2\n",
    "demographic.loc[demographic.tech_ad.isin([0,8,6]), 'tech_right'] = 3\n",
    "demographic.loc[demographic.tech_ad.isnull(), 'tech_right'] = None\n",
    "\n",
    "demographic[\"tech_left\"] = 4\n",
    "demographic.loc[demographic.tech_as==7, 'tech_left'] = 0\n",
    "demographic.loc[demographic.tech_as==3, 'tech_left'] = 1\n",
    "demographic.loc[demographic.tech_as.isin([1,2,4,5,10]), 'tech_left'] = 2\n",
    "demographic.loc[demographic.tech_as.isin([0,8,6]), 'tech_left'] = 3\n",
    "demographic.loc[demographic.tech_as.isnull(), 'tech_left'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    8800\n",
       "3.0    5604\n",
       "0.0    2452\n",
       "4.0      69\n",
       "1.0      21\n",
       "Name: tech_left, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.tech_left.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    8663\n",
       "3.0    6132\n",
       "0.0    2076\n",
       "4.0      88\n",
       "1.0      27\n",
       "Name: tech_right, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.tech_right.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute valid missing values for hearing loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.loc[demographic.type_hl_ad==5, 'type_hl_ad'] = None\n",
    "demographic.loc[demographic.type_hl_as==5, 'type_hl_ad'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `degree_hl`, which is the maximum level of hearing loss in either ear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fonnescj/anaconda3/envs/early_intervention/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in maximum\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "demographic[\"degree_hl\"] = np.maximum(demographic.degree_hl_ad, demographic.degree_hl_as)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create compound indicator variable for each technology (Baha, Hearing aid, Chochlear implant): \n",
    "\n",
    "* 0=none\n",
    "* 1=one ear\n",
    "* 2=both ears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oad:\n",
      "0.0    5923\n",
      "1.0       5\n",
      "2.0       1\n",
      "Name: oad, dtype: int64\n",
      "There are 1765 null values for OAD\n",
      "\n",
      "hearing_aid:\n",
      "2.0    2817\n",
      "0.0    2030\n",
      "1.0    1052\n",
      "Name: hearing_aid, dtype: int64\n",
      "There are 1814 null values for hearing_aid\n",
      "\n",
      "cochlear:\n",
      "0.0    4062\n",
      "2.0    1140\n",
      "1.0     727\n",
      "Name: cochlear, dtype: int64\n",
      "There are 1765 null values for cochlear\n",
      "18800\n"
     ]
    }
   ],
   "source": [
    "demographic[\"oad\"] = 0\n",
    "demographic.oad = demographic.oad.astype(object)\n",
    "demographic.loc[(demographic.tech_right==1) | (demographic.tech_left==1), 'oad'] = 1\n",
    "demographic.loc[(demographic.tech_right==1) & (demographic.tech_left==1), 'oad'] = 2\n",
    "demographic.loc[(demographic.tech_right.isnull()) & (demographic.tech_left.isnull()), 'oad'] = None\n",
    "print(\"oad:\")\n",
    "print(demographic.drop_duplicates(subset='study_id').oad.value_counts())\n",
    "print(\"There are {0} null values for OAD\".format(sum(demographic.oad.isnull())))\n",
    "\n",
    "demographic[\"hearing_aid\"] = 0\n",
    "demographic.hearing_aid = demographic.hearing_aid.astype(object)\n",
    "demographic.loc[(demographic.tech_right==2) | (demographic.tech_left==2), 'hearing_aid'] = 1\n",
    "demographic.loc[(demographic.tech_right==2) & (demographic.tech_left==2), 'hearing_aid'] = 2\n",
    "demographic.loc[(demographic.tech_right.isnull()) & (demographic.tech_right.isnull()), 'hearing_aid'] = None\n",
    "print(\"\\nhearing_aid:\")\n",
    "print(demographic.drop_duplicates(subset='study_id').hearing_aid.value_counts())\n",
    "print(\"There are {0} null values for hearing_aid\".format(sum(demographic.hearing_aid.isnull())))\n",
    "\n",
    "demographic[\"cochlear\"] = 0\n",
    "demographic.cochlear = demographic.cochlear.astype(object)\n",
    "demographic.loc[(demographic.tech_right==3) | (demographic.tech_left==3), 'cochlear'] = 1\n",
    "demographic.loc[(demographic.tech_right==3) & (demographic.tech_left==3), 'cochlear'] = 2\n",
    "demographic.loc[(demographic.tech_right.isnull()) & (demographic.tech_left.isnull()), 'cochlear'] = None\n",
    "print(\"\\ncochlear:\")\n",
    "print(demographic.drop_duplicates(subset='study_id').cochlear.value_counts())\n",
    "print(\"There are {0} null values for cochlear\".format(sum(demographic.cochlear.isnull())))\n",
    "print(len(demographic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify bilateral and bimodal individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic[\"unilateral_ci\"] = demographic.cochlear==1\n",
    "demographic[\"bilateral_ci\"] = demographic.cochlear==2\n",
    "demographic[\"unilateral_ha\"] = demographic.hearing_aid==1\n",
    "demographic[\"bilateral_ha\"] = demographic.hearing_aid==2\n",
    "demographic[\"bimodal\"] = (demographic.cochlear==1) & (demographic.hearing_aid==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4617, 7125, 1725, 2502)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.bilateral_ci.sum(), demographic.bilateral_ha.sum(), demographic.bimodal.sum(), demographic.unilateral_ci.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unilateral_ci     727\n",
       "bilateral_ci     1140\n",
       "bilateral_ha     2817\n",
       "bimodal           446\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.drop_duplicates(subset='study_id')[['unilateral_ci','bilateral_ci', \n",
    "                                               'bilateral_ha',\n",
    "                                               'bimodal']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variable that identifies bilateral (0), bilateral HA left (1), bilateral HA right (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values for tech\n"
     ]
    }
   ],
   "source": [
    "demographic['tech'] = 0\n",
    "demographic.loc[(demographic.bimodal) & (demographic.tech_left==2), 'tech'] = 1\n",
    "demographic.loc[(demographic.bimodal) & (demographic.tech_right==2), 'tech'] = 2\n",
    "print(\"There are {0} null values for tech\".format(sum(demographic.tech.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    7125\n",
       "3    4617\n",
       "4    1725\n",
       "1    1463\n",
       "0     757\n",
       "8      15\n",
       "2      11\n",
       "7       6\n",
       "5       1\n",
       "Name: implant_category, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic[\"implant_category\"] = None\n",
    "demographic.loc[(demographic.cochlear==1) & (demographic.hearing_aid==0) & (demographic.oad==0), \n",
    "                'implant_category'] = 0\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==1) & (demographic.oad==0), \n",
    "                'implant_category'] = 1\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==0) & (demographic.oad==1), \n",
    "                'implant_category'] = 2\n",
    "demographic.loc[(demographic.cochlear==2) & (demographic.hearing_aid==0) & (demographic.oad==0), \n",
    "                'implant_category'] = 3\n",
    "demographic.loc[(demographic.cochlear==1) & (demographic.hearing_aid==1) & (demographic.oad==0), \n",
    "                'implant_category'] = 4\n",
    "demographic.loc[(demographic.cochlear==1) & (demographic.hearing_aid==0) & (demographic.oad==1), \n",
    "                'implant_category'] = 5\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==2) & (demographic.oad==0), \n",
    "                'implant_category'] = 6\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==1) & (demographic.oad==1), \n",
    "                'implant_category'] = 7\n",
    "demographic.loc[(demographic.cochlear==0) & (demographic.hearing_aid==0) & (demographic.oad==2), \n",
    "                'implant_category'] = 8\n",
    "demographic.implant_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age when hearing loss diagnosed** Data are entered inconsistently here, so we have to go in and replace non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need this anymore\n",
    "# demographic['age_diag'] = demographic.onset_1.replace({'birth': 0, 'R- Birth L-16mo': 0, 'birth - 3': 0, 'at birth': 0, 'NBHS': 0, \n",
    "#                              'at Birth': 0, '1-2': 1.5, '2-3': 2.5, '0-3': 1.5}).astype(float)\n",
    "demographic['age_diag'] = demographic.onset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of null values for `age_diag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3941"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.age_diag.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['sex'] = demographic.male.replace({0:'Female', 1:'Male'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Child has another diagnosed disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic['known_synd'] = (demographic.synd_cause == 0)\n",
    "# Unknown or suspected\n",
    "demographic.loc[demographic.synd_cause > 1, 'known_synd'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If either known syndrome or secondary diagnosis\n",
    "demographic['synd_or_disab'] = demographic.apply(lambda x: x['secondary_diagnosis'] or x['known_synd'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing sibling counts were properly encoded as `None` (missing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.loc[demographic.sib==4, 'sib'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reduced the number of race categories, pooling those that were neither caucasian, black, hispanic or asian to \"other\", due to small sample sizes for these categories. Category 7 (unknown) was recoded as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_race:\n",
      "0.0    9648\n",
      "2.0    3422\n",
      "1.0    1737\n",
      "3.0    1384\n",
      "6.0     996\n",
      "8.0     646\n",
      "7.0     319\n",
      "4.0      76\n",
      "5.0      52\n",
      "Name: _race, dtype: int64\n",
      "race:\n",
      "0.0    9648\n",
      "2.0    3422\n",
      "4.0    1770\n",
      "1.0    1737\n",
      "3.0    1384\n",
      "Name: race, dtype: int64\n",
      "There are 839 null values for race\n"
     ]
    }
   ],
   "source": [
    "races = [\"Caucasian\", \"Black or African American\", \"Hispanic or Latino\", \"Asian\", \"Other\"]\n",
    "demographic = demographic.rename(columns={\"race\":\"_race\"})\n",
    "demographic[\"race\"] = demographic._race.copy()\n",
    "demographic.loc[demographic.race==7, 'race'] = None\n",
    "demographic.loc[demographic.race>3, 'race'] = 4\n",
    "print(\"_race:\")\n",
    "print(demographic._race.value_counts())\n",
    "print(\"race:\")\n",
    "print(demographic.race.value_counts())\n",
    "print(\"There are {0} null values for race\".format(sum(demographic.race.isnull())))\n",
    "# Replace with recoded column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode implant technology variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_cats = [\"None\", \"Baha\", \"Hearing aid\", \"Cochlear\", \"Other\"]\n",
    "\n",
    "demographic[\"tech_right\"] = demographic.tech_ad.copy()\n",
    "demographic.loc[demographic.tech_right==6, 'tech_right'] = 0\n",
    "demographic.loc[demographic.tech_right==4, 'tech_right'] = 1\n",
    "demographic.loc[demographic.tech_right==5, 'tech_right'] = 1\n",
    "demographic.loc[demographic.tech_right==3, 'tech_right'] = 2\n",
    "demographic.loc[demographic.tech_right==7, 'tech_right'] = 3\n",
    "demographic.loc[demographic.tech_right==8, 'tech_right'] = 3\n",
    "demographic.loc[demographic.tech_right==9, 'tech_right'] = 4\n",
    "demographic.tech_right = np.abs(demographic.tech_right - 3)\n",
    "\n",
    "demographic[\"tech_left\"] = demographic.tech_as.copy()\n",
    "demographic.loc[demographic.tech_left==6, 'tech_left'] = 0\n",
    "demographic.loc[demographic.tech_left==4, 'tech_left'] = 1\n",
    "demographic.loc[demographic.tech_left==5, 'tech_left'] = 1\n",
    "demographic.loc[demographic.tech_left==3, 'tech_left'] = 2\n",
    "demographic.loc[demographic.tech_left==7, 'tech_left'] = 3\n",
    "demographic.loc[demographic.tech_left==8, 'tech_left'] = 3\n",
    "demographic.loc[demographic.tech_left==9, 'tech_left'] = 4\n",
    "demographic.tech_left = np.abs(demographic.tech_left - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic.to_csv(DATA_DIR+'demographics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning expressive vocabulary dataset\n",
    "\n",
    "We converted the expressive vocabulary dataset to \"long\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values for test_type\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "expressive[\"test_type\"] = None\n",
    "EOWPVT = expressive.eowpvt_ss.notnull()\n",
    "EVT = expressive.evt_ss.notnull()\n",
    "expressive = expressive[EOWPVT | EVT]\n",
    "expressive.loc[EOWPVT & EVT, \"test_type\"] = \"EOWPVT and EVT\"\n",
    "expressive.loc[EOWPVT & ~EVT, \"test_type\"] = \"EOWPVT\"\n",
    "expressive.loc[~EOWPVT & EVT, \"test_type\"] = \"EVT\"\n",
    "print(\"There are {0} null values for test_type\".format(sum(expressive[\"test_type\"].isnull())))\n",
    "\n",
    "expressive[\"score\"] = expressive.eowpvt_ss\n",
    "expressive.loc[~EOWPVT & EVT, \"score\"] = expressive.evt_ss[~EOWPVT & EVT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVT               4704\n",
       "EOWPVT            3356\n",
       "EOWPVT and EVT     212\n",
       "Name: test_type, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressive.test_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive[\"school\"] = expressive.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age was taken to be the EOWPVT age if there are both test types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive[\"age_test\"] = expressive.age_test_eowpvt\n",
    "expressive.loc[expressive.age_test.isnull(), 'age_test'] = expressive.age_test_evt[expressive.age_test.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we dropped unwanted columns and added a domain identification column for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive[\"domain\"] = \"Expressive Vocabulary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive.to_csv(DATA_DIR+'expressive_vocabulary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning receptive vocabulary dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the receptive vocabulary data table to \"long\" format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 null values for test_type\n"
     ]
    }
   ],
   "source": [
    "# Test type\n",
    "receptive[\"test_type\"] = None\n",
    "PPVT = receptive.ppvt_ss.notnull()\n",
    "ROWPVT = receptive.rowpvt_ss.notnull()\n",
    "receptive = receptive[PPVT | ROWPVT]\n",
    "receptive.loc[PPVT & ROWPVT, \"test_type\"] = \"PPVT and ROWPVT\"\n",
    "receptive.loc[PPVT & ~ROWPVT, \"test_type\"] = \"PPVT\"\n",
    "receptive.loc[~PPVT & ROWPVT, \"test_type\"] = \"ROWPVT\"\n",
    "print(\"There are {0} null values for test_type\".format(sum(receptive[\"test_type\"].isnull())))\n",
    "\n",
    "receptive[\"score\"] = receptive.ppvt_ss\n",
    "receptive.loc[~PPVT & ROWPVT, \"score\"] = receptive.rowpvt_ss[~PPVT & ROWPVT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `school` variable was added, which is the first four columns of the `study_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive[\"school\"] = receptive.study_id.str.slice(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age was taken to be the PPVT age if there are both test types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive[\"age_test\"] = receptive.age_test_ppvt\n",
    "receptive.loc[receptive.age_test.isnull(), 'age_test'] = receptive.age_test_rowpvt[receptive.age_test.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 null values for age_test\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {0} null values for age_test\".format(sum(receptive.age_test.isnull())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we dropped unwanted columns and added a domain identification column for merging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive[\"domain\"] = \"Receptive Vocabulary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3669,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive.study_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive.to_csv(DATA_DIR+'receptive_vocabulary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets\n",
    "\n",
    "The four datasets were mereged into a single table. First, we concatenate the test scores data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = pd.concat([articulation, expressive, receptive, language])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform a merge between the demographic data and the test scores data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr = pd.merge(demographic, test_scores, on=[\"study_id\", \"redcap_event_name\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>male</th>\n",
       "      <th>_race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>_mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>parent_hl</th>\n",
       "      <th>...</th>\n",
       "      <th>domain</th>\n",
       "      <th>eowpvt_ss</th>\n",
       "      <th>evt_ss</th>\n",
       "      <th>gf2_ss</th>\n",
       "      <th>ppvt_ss</th>\n",
       "      <th>rowpvt_ss</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>test_name</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47639</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Receptive Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47640</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47641</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Articulation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Goldman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47642</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Expressive Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47643</th>\n",
       "      <td>year_9_complete_71_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Receptive Vocabulary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1147</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PPVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              redcap_event_name  academic_year_rv   hl  male  _race  \\\n",
       "47639  year_9_complete_71_arm_1            2013.0  0.0   1.0    8.0   \n",
       "47640  year_9_complete_71_arm_1            2011.0  0.0   0.0    3.0   \n",
       "47641  year_9_complete_71_arm_1            2011.0  0.0   1.0    0.0   \n",
       "47642  year_9_complete_71_arm_1            2011.0  0.0   1.0    0.0   \n",
       "47643  year_9_complete_71_arm_1            2011.0  0.0   1.0    0.0   \n",
       "\n",
       "       prim_lang  sib  _mother_ed  father_ed  parent_hl    ...      \\\n",
       "47639        6.0  3.0         6.0        6.0        4.0    ...       \n",
       "47640        0.0  0.0         6.0        6.0        4.0    ...       \n",
       "47641        0.0  1.0         3.0        2.0        0.0    ...       \n",
       "47642        0.0  1.0         3.0        2.0        0.0    ...       \n",
       "47643        0.0  1.0         3.0        2.0        0.0    ...       \n",
       "\n",
       "                      domain  eowpvt_ss  evt_ss  gf2_ss  ppvt_ss  rowpvt_ss  \\\n",
       "47639   Receptive Vocabulary        NaN     NaN     NaN     84.0        NaN   \n",
       "47640                    NaN        NaN     NaN     NaN      NaN        NaN   \n",
       "47641           Articulation        NaN     NaN    95.0      NaN        NaN   \n",
       "47642  Expressive Vocabulary        NaN    99.0     NaN      NaN        NaN   \n",
       "47643   Receptive Vocabulary        NaN     NaN     NaN     92.0        NaN   \n",
       "\n",
       "       school  score  test_name  test_type  \n",
       "47639    1147     84        NaN       PPVT  \n",
       "47640     NaN    NaN        NaN        NaN  \n",
       "47641    1147     95        NaN    Goldman  \n",
       "47642    1147     99        NaN        EVT  \n",
       "47643    1147     92        NaN       PPVT  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsl_dr.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert score to floating-point number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr.score = lsl_dr.score.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr.to_csv(DATA_DIR+'lsl_dr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47644, 97)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsl_dr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
