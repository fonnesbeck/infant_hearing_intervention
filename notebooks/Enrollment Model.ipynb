{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact of age of enrollment on the Five Domains of Speech-Language in Children with Hearing Loss at age 4 years\n",
    "\n",
    "Paper 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and set options\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "\n",
    "sns.set(context='notebook', style='ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr = (pd.read_csv('../data/clean/lsl_dr.csv', index_col=0, low_memory=False)\n",
    "                  .rename({'onset_1':'identify_mo'}, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redcap_event_name</th>\n",
       "      <th>academic_year_rv</th>\n",
       "      <th>hl</th>\n",
       "      <th>male</th>\n",
       "      <th>_race</th>\n",
       "      <th>prim_lang</th>\n",
       "      <th>sib</th>\n",
       "      <th>_mother_ed</th>\n",
       "      <th>father_ed</th>\n",
       "      <th>par1_ed</th>\n",
       "      <th>...</th>\n",
       "      <th>gf3_sis_ss</th>\n",
       "      <th>gf3_siw_ss</th>\n",
       "      <th>gf_version</th>\n",
       "      <th>ppvt_f</th>\n",
       "      <th>ppvt_ss</th>\n",
       "      <th>rowpvt_ss</th>\n",
       "      <th>school</th>\n",
       "      <th>score</th>\n",
       "      <th>test_name</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EOWPVT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>51.0</td>\n",
       "      <td>PLS</td>\n",
       "      <td>receptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>60.0</td>\n",
       "      <td>PLS</td>\n",
       "      <td>expressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>54.0</td>\n",
       "      <td>PLS</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>initial_assessment_arm_1</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EOWPVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          redcap_event_name  academic_year_rv   hl  male  _race  prim_lang  \\\n",
       "0  initial_assessment_arm_1            2002.0  0.0   0.0    0.0        0.0   \n",
       "1  initial_assessment_arm_1            2002.0  0.0   0.0    0.0        0.0   \n",
       "2  initial_assessment_arm_1            2002.0  0.0   0.0    0.0        0.0   \n",
       "3  initial_assessment_arm_1            2002.0  0.0   0.0    0.0        0.0   \n",
       "4  initial_assessment_arm_1            2011.0  0.0   1.0    3.0        0.0   \n",
       "\n",
       "   sib  _mother_ed  father_ed  par1_ed  ...  gf3_sis_ss  gf3_siw_ss  \\\n",
       "0  1.0         6.0        6.0      NaN  ...         NaN         NaN   \n",
       "1  1.0         6.0        6.0      NaN  ...         NaN         NaN   \n",
       "2  1.0         6.0        6.0      NaN  ...         NaN         NaN   \n",
       "3  1.0         6.0        6.0      NaN  ...         NaN         NaN   \n",
       "4  1.0         5.0        5.0      NaN  ...         NaN         NaN   \n",
       "\n",
       "   gf_version  ppvt_f  ppvt_ss  rowpvt_ss  school  score  test_name  \\\n",
       "0         NaN     NaN      NaN        NaN     101   58.0        NaN   \n",
       "1         NaN     NaN      NaN        NaN     101   51.0        PLS   \n",
       "2         NaN     NaN      NaN        NaN     101   60.0        PLS   \n",
       "3         NaN     NaN      NaN        NaN     101   54.0        PLS   \n",
       "4         NaN     NaN      NaN        NaN     626   96.0        NaN   \n",
       "\n",
       "    test_type  \n",
       "0      EOWPVT  \n",
       "1   receptive  \n",
       "2  expressive  \n",
       "3       total  \n",
       "4      EOWPVT  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsl_dr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator for non-profound hearing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['deg_hl_below6'] = lsl_dr.degree_hl<6\n",
    "lsl_dr.loc[lsl_dr.degree_hl.isnull(), 'deg_hl_below6'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator for first intervention outside OPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['int_outside_option'] = lsl_dr.age > lsl_dr.age_int\n",
    "lsl_dr.loc[lsl_dr.age < lsl_dr.age_int, 'int_outside_option'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator for high school graduation of mother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['mother_college'] = lsl_dr.mother_ed >= 3\n",
    "lsl_dr.loc[lsl_dr.mother_ed.isnull(), 'mother_college'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create age in years variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['age_years'] = lsl_dr.age/12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create school index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_unique = np.sort(lsl_dr.school.unique())\n",
    "school_lookup = dict(zip(schools_unique, range(len(schools_unique))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['school_idx'] = lsl_dr.school.replace(school_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create student index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_unique = np.sort(lsl_dr.study_id.unique())\n",
    "student_lookup = dict(zip(student_unique, range(len(student_unique))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['student_idx'] = lsl_dr.study_id.replace(student_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add expressive and receptive to langauge test domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr.loc[(lsl_dr.domain=='Language') & (lsl_dr.test_type=='receptive'), \n",
    "           'domain'] = 'Receptive Language'\n",
    "lsl_dr.loc[(lsl_dr.domain=='Language') & (lsl_dr.test_type=='expressive'), \n",
    "           'domain'] = 'Expressive Language'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr['ident_3mo'] = lsl_dr.identify_mo <=3\n",
    "lsl_dr.loc[lsl_dr.identify_mo.isnull(), 'ident_3mo'] = None\n",
    "lsl_dr['int_6mo'] = lsl_dr.age_int <= 6\n",
    "lsl_dr.loc[lsl_dr.identify_mo.isnull(), 'int_6mo'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop records with missing race and age at ernollment, since there is less than 1% of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsl_dr = lsl_dr.dropna(subset=['race', 'age_years', 'int_outside_option'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclusions\n",
    "\n",
    "Drop non-english and other disabilities, filter for hearing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_etiology = (lsl_dr[['etiology_3___2', 'etiology_3___4', 'etiology_3___5', 'etiology_3___6', 'etiology_3___9',\n",
    "       'etiology_oth___1', 'etiology_oth___3', 'etiology_oth___4', 'etiology_oth___8', 'etiology_oth___9']]\n",
    "                      .sum(1).astype(bool))\n",
    "NON_ENGLISH = lsl_dr.non_english.astype(bool) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECONDARY_DISABILITY = (lsl_dr.synd_or_disab.astype(bool) \n",
    "     | ~(lsl_dr.etiology_2.isin([0,4]))\n",
    "     | (lsl_dr.etiology_2.isnull() & other_etiology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no secondary distability, english first language\n",
    "inclusion_mask_1 = ((lsl_dr.degree_hl!=0)\n",
    "                  & ~SECONDARY_DISABILITY\n",
    "                  & ~NON_ENGLISH)\n",
    "\n",
    "# secondary disability, english first language\n",
    "inclusion_mask_2 = ((lsl_dr.degree_hl!=0)\n",
    "                  & SECONDARY_DISABILITY\n",
    "                  & ~NON_ENGLISH)\n",
    "\n",
    "# no secondary disability, non-english\n",
    "inclusion_mask_3 = ((lsl_dr.degree_hl!=0)\n",
    "                  & ~SECONDARY_DISABILITY\n",
    "                  & NON_ENGLISH)\n",
    "\n",
    "# secondary disability, non-english\n",
    "inclusion_mask_4 = ((lsl_dr.degree_hl!=0)\n",
    "                  & SECONDARY_DISABILITY\n",
    "                  & NON_ENGLISH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {'no secondary disability, english': inclusion_mask_1, \n",
    "         'secondary disability, english': inclusion_mask_2, \n",
    "         'no secondary disability, non-english': inclusion_mask_3, \n",
    "         'secondary disability, non-english': inclusion_mask_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = ['score', 'student_idx', 'school_idx', 'male', 'sib', 'family_inv', 'race', 'age_test', \n",
    "              'domain', 'deg_hl_below6', 'mother_college', 'age_years', 'test_type', 'time', 'bilateral_ci',\n",
    "              'bilateral_ha', 'unilateral_ci', 'unilateral_ha', 'bimodal', 'age_amp',\n",
    "              'ident_3mo', 'int_outside_option', 'int_6mo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'no secondary disability, english'\n",
    "filename_stub = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31272"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_subset = lsl_dr.loc[masks[group], covariates].copy().dropna(subset=['time', 'score', 'age_test']) \n",
    "analysis_subset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_students = analysis_subset.drop_duplicates(subset='student_idx')\n",
    "unique_students.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mother_college    0.25\n",
       "age_amp           0.15\n",
       "int_6mo           0.12\n",
       "ident_3mo         0.12\n",
       "family_inv        0.09\n",
       "deg_hl_below6     0.07\n",
       "sib               0.05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_prop = analysis_subset.isnull().mean()\n",
    "null_prop[null_prop>0].round(2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[0.4, --, 5.0],\n",
       "             mask=[False,  True, False],\n",
       "       fill_value=0.5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fillna(x, value):\n",
    "    x_masked = np.ma.masked_invalid(x)\n",
    "    np.ma.set_fill_value(x_masked, value)\n",
    "    return x_masked\n",
    "\n",
    "fillna(np.array([0.4, np.nan, 5]), 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Bernoulli, Normal, Uniform, Dirichlet, Categorical, Beta, HalfCauchy\n",
    "from pymc3 import Gamma, Exponential, Multinomial, HalfNormal, NormalMixture, Lognormal\n",
    "from pymc3 import Model, Deterministic, Metropolis\n",
    "from numpy.ma import masked_values, set_fill_value, masked_invalid\n",
    "import theano.tensor as tt\n",
    "from theano import shared\n",
    "\n",
    "def generate_model(dataset, cohort_age=4):\n",
    "    \n",
    "    if cohort_age==2:\n",
    "        mask = (dataset.age_test>=24) & (dataset.age_test<36)\n",
    "    elif cohort_age==3:\n",
    "        mask = (dataset.age_test>=36) & (dataset.age_test<48)\n",
    "    elif cohort_age==4:\n",
    "        mask = (dataset.age_test>=48) & (dataset.age_test<60)\n",
    "    elif cohort_age==5:\n",
    "        mask = (dataset.age_test>=60) & (dataset.age_test<72)\n",
    "    elif cohort_age==6:\n",
    "        mask = (dataset.age_test>=72) & (dataset.age_test<84)\n",
    "    else:\n",
    "        print('Invalid age!')\n",
    "        return\n",
    "    \n",
    "    # Generate mean scores\n",
    "    mean_scores = dataset[mask].groupby('student_idx').score.mean()\n",
    "    dataset_unique = dataset[mask].drop_duplicates(subset='student_idx')\n",
    "    dataset_unique.set_index('student_idx').drop('score', axis=1).join(mean_scores)\n",
    "    assert not dataset_unique.score.isnull().sum()\n",
    "    \n",
    "    (family_inv, school, time, sib,\n",
    "             mother_college, age_amp,\n",
    "             ident_3mo,\n",
    "             int_outside_option, int_6mo, score) = dataset_unique[['family_inv', \n",
    "                                                     'school_idx', \n",
    "                                                    'time', 'sib', 'mother_college', \n",
    "                                                    'age_amp', \n",
    "                                                    'ident_3mo', 'int_outside_option', 'int_6mo',\n",
    "                                                                   'score']].astype(float).T.values\n",
    "\n",
    "    int_option = (~int_outside_option.astype(bool)).astype(int)\n",
    "\n",
    "    with Model() as model:\n",
    "        \n",
    "        # Imputation of age of amplification\n",
    "        if np.isnan(age_amp).sum():\n",
    "            m_age_amp = Normal(\"m_age_amp\", 0, sd=5, shape=2)\n",
    "            s_age_amp = Exponential(\"s_age_amp\", 1)\n",
    "            p_age_amp = Beta('p_age_amp', 1, 1)\n",
    "            _x_age_amp = NormalMixture('x_age_amp', [p_age_amp, 1-p_age_amp], m_age_amp, \n",
    "                                       sd=s_age_amp,\n",
    "                                       observed=masked_invalid(np.log(age_amp+0.1)))\n",
    "            x_age_amp = (tt.exp(_x_age_amp) - 0.1) / 12\n",
    "        else:\n",
    "            x_age_amp = age_amp / 12\n",
    "        \n",
    "        # Imputation of family involvement\n",
    "        if np.isnan(family_inv).sum():\n",
    "            p_family_inv = Dirichlet(\"p_family_inv\", np.ones(5))\n",
    "            x_family_inv = Categorical('x_family_inv', p_family_inv, \n",
    "                                       observed=masked_invalid(family_inv))\n",
    "        else:\n",
    "            x_family_inv = family_inv\n",
    "            \n",
    "        # Imputation of siblings\n",
    "        if np.isnan(sib).sum():\n",
    "            n_sib_cats = len(dataset.sib.unique())\n",
    "            p_sib = Dirichlet(\"p_sib\", np.ones(n_sib_cats))\n",
    "            x_sib = Categorical('x_sib', p_sib, observed=masked_invalid(sib))\n",
    "        else:\n",
    "            x_sib = sib\n",
    "            \n",
    "        # Imputation of 3 month identification\n",
    "        if np.isnan(ident_3mo).sum():\n",
    "            p_3mo = Beta(\"p_3mo\", 1, 1)\n",
    "            x_3mo = Bernoulli('x_3mo', p_3mo, observed=masked_invalid(ident_3mo))\n",
    "        else:\n",
    "            x_3mo = ident_3mo\n",
    "            \n",
    "        # Imputation of 6 month intervention\n",
    "        if np.isnan(int_6mo).sum():\n",
    "            p_6mo = Beta(\"p_6mo\", 1, 1)\n",
    "            x_6mo = Bernoulli('x_6mo', p_6mo, observed=masked_invalid(int_6mo))\n",
    "        else:\n",
    "            x_6mo = int_6mo\n",
    "            \n",
    "        # Indices to school random effects\n",
    "        unique_schools = np.unique(school)\n",
    "        school_index = [list(unique_schools).index(s) for s in school]\n",
    "\n",
    "        # School random effect (non-centered parameterization)\n",
    "        Î¼_school = Normal('Î¼_school', 90, sd=10)\n",
    "        Ïƒ_school = Exponential(\"Ïƒ_school\", 1)\n",
    "        z_school = Normal('z_school', mu=0, sd=1, shape=len(unique_schools))\n",
    "        Î±_school = Deterministic(\"Î±_school\", Î¼_school + z_school*Ïƒ_school)\n",
    "        \n",
    "        # Random intercepts\n",
    "        intercept = Î±_school[school_index]\n",
    "\n",
    "        # Covariates\n",
    "        X = [x_age_amp, \n",
    "             x_family_inv, \n",
    "             x_sib,\n",
    "             mother_college, \n",
    "             time,\n",
    "             x_3mo,\n",
    "             x_6mo,\n",
    "             int_option,\n",
    "             int_option*x_6mo]\n",
    "        \n",
    "\n",
    "        # Fixed effects\n",
    "        Î² = Normal(\"Î²\", 0, sd=100, shape=len(X))\n",
    "        Î¸ = intercept + Î².dot(tt.stack(X))\n",
    "        Ïƒ = HalfNormal(\"Ïƒ\", sd=25, testval=100)\n",
    "        score_like = Normal(\"score_like\", mu=Î¸, sd=Ïƒ, observed=score)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive Language Test Score Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6013"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_language_dataset = analysis_subset[(analysis_subset.domain=='Receptive Language')]\n",
    "\n",
    "receptive_language_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/model.py:1331: UserWarning: Data in x_age_amp contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, UserWarning)\n",
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/model.py:1331: UserWarning: Data in x_family_inv contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, UserWarning)\n",
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/model.py:1331: UserWarning: Data in x_sib contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, UserWarning)\n",
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/model.py:1331: UserWarning: Data in x_3mo contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, UserWarning)\n",
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/model.py:1331: UserWarning: Data in x_6mo contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "receptive_language_4 = generate_model(receptive_language_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "tuning = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mother_college    0.25\n",
    "age_amp           0.15\n",
    "int_6mo           0.12\n",
    "ident_3mo         0.12\n",
    "family_inv        0.09\n",
    "deg_hl_below6     0.07\n",
    "sib               0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_age_amp                         -5.06\n",
      "s_age_amp_log__                   -1.06\n",
      "p_age_amp_logodds__               -1.39\n",
      "x_age_amp_missing                  0.00\n",
      "p_family_inv_stickbreaking__      -4.87\n",
      "x_family_inv_missing               0.00\n",
      "p_sib_stickbreaking__             -4.87\n",
      "x_sib_missing                      0.00\n",
      "p_3mo_logodds__                   -1.39\n",
      "x_3mo_missing                      0.00\n",
      "p_6mo_logodds__                   -1.39\n",
      "x_6mo_missing                      0.00\n",
      "Î¼_school                          -3.22\n",
      "Ïƒ_school_log__                    -1.06\n",
      "z_school                         -37.68\n",
      "Î²                                -49.72\n",
      "Ïƒ_log__                           -6.84\n",
      "x_age_amp                      -6419.58\n",
      "x_family_inv                   -1633.58\n",
      "x_sib                          -1633.58\n",
      "x_3mo                           -703.54\n",
      "x_6mo                           -703.54\n",
      "score_like                          NaN\n",
      "Name: Log-probability of test_point, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "CHECK_MODEL = True\n",
    "\n",
    "if CHECK_MODEL:\n",
    "    print(receptive_language_4.check_test_point())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "CompoundStep\n",
      ">NUTS: [Ïƒ, Î², z_school, Ïƒ_school, Î¼_school, p_6mo, p_3mo, p_sib, p_family_inv, x_age_amp_missing, p_age_amp, s_age_amp, m_age_amp]\n",
      ">CategoricalGibbsMetropolis: [x_sib_missing, x_family_inv_missing]\n",
      ">BinaryGibbsMetropolis: [x_3mo_missing, x_6mo_missing]\n",
      "Sampling 2 chains:   0%|          | 0/10000 [00:00<?, ?draws/s]INFO (theano.gof.compilelock): Waiting for existing lock by process '4149' (I am process '4148')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /home/fonnesbeck_gmail_com/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.6--3.7.3-64/lock_dir\n",
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "\n",
      "Bad initial energy, check any log probabilities that are inf or -inf, nan or very small:\n",
      "score_like   NaN\n"
     ]
    },
    {
     "ename": "ParallelSamplingError",
     "evalue": "Bad initial energy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/parallel_sampling.py\", line 160, in _start_loop\n    point, stats = self._compute_point()\n  File \"/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/parallel_sampling.py\", line 191, in _compute_point\n    point, stats = self._step_method.step(self._point)\n  File \"/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/step_methods/compound.py\", line 27, in step\n    point, state = method.step(point)\n  File \"/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/step_methods/arraystep.py\", line 247, in step\n    apoint, stats = self.astep(array)\n  File \"/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/step_methods/hmc/base_hmc.py\", line 144, in astep\n    raise SamplingError(\"Bad initial energy\")\npymc3.exceptions.SamplingError: Bad initial energy\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;31mSamplingError\u001b[0m: Bad initial energy",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParallelSamplingError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f8a155def4b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mreceptive_language_4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrec_lang_4_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0m_print_step_hierarchy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[0;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                     if (trace.supports_sampler_stats\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dev/lib/python3.7/site-packages/pymc3/parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[0;34m(processes, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chain %s failed.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mold_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"writing_done\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParallelSamplingError\u001b[0m: Bad initial energy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fonnesbeck_gmail_com/anaconda3/envs/dev/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from pymc3 import sample\n",
    "\n",
    "with receptive_language_4:\n",
    "    rec_lang_4_trace = sample(iterations, tune=tuning, chains=2, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Age at amplification',\n",
    "          'Family Involvement Score', \n",
    "          'Number of siblings',\n",
    "          'Mother with College Ed',\n",
    "          'Years in program',\n",
    "          'Identified <= 3mo',          \n",
    "          'Intervention <= 6mo',\n",
    "          'Intervention with OPTION',\n",
    "          'Interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = az.plot_forest(rec_lang_4_trace, \n",
    "               var_names=['Î²'],\n",
    "              combined=True)\n",
    "axes[0].set_title('Receptive Language')\n",
    "axes[0].vlines(0, *axes[0].get_ylim(), linestyles='dotted')\n",
    "axes[0].set_yticklabels(labels[::-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import forestplot\n",
    "\n",
    "forestplot(rec_lang_4_trace, varnames=['Î²'], ylabels=labels, main='Receptive Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(rec_lang_4_trace, varnames=['Î±_school'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import effective_n\n",
    "\n",
    "effective_n(rec_lang_4_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import energyplot\n",
    "\n",
    "energyplot(rec_lang_4_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(rec_lang_4_trace, varnames=['Î²'], ylabels=labels, main='Receptive Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(rec_lang_4_trace, varnames=['Î²_race'], ylabels=['Black', 'Hispanic', 'Asian', 'Other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The school random effect standard deviation is a measure of how variable scores are among schools. The estimated standard deviation is about 4 points for this domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import traceplot\n",
    "\n",
    "traceplot(rec_lang_4_trace, varnames=['Ïƒ_school'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import summary\n",
    "\n",
    "summary(rec_lang_4_trace, varnames=['Î²']).set_index(pd.Index(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(rec_lang_4_trace, varnames=[\"predictions\"], rhat=False, \n",
    "           ylabels=['Student {}'.format(i) for i in range(1,5)],\n",
    "           main='Predicted receptive language scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressive Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_language_dataset = analysis_subset[(analysis_subset.domain=='Expressive Language')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_language_4 = generate_model(expressive_language_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with expressive_language_4:\n",
    "    \n",
    "    exp_lang_4_trace = sample(iterations, tune=tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(exp_lang_4_trace, varnames=['Î²'], ylabels=labels, main='Receptive Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(exp_lang_4_trace, varnames=[\"predictions\"], rhat=False, \n",
    "           ylabels=['Student {}'.format(i) for i in range(1,5)],\n",
    "           main='Predicted receptive language scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articulation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation_dataset = analysis_subset[(analysis_subset.domain=='Articulation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articulation_4 = generate_model(articulation_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with articulation_4:\n",
    "    \n",
    "    artic_4_trace = sample(iterations, tune=tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(artic_4_trace, varnames=['Î²'], ylabels=labels, main='Receptive Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(artic_4_trace, varnames=[\"predictions\"], rhat=False, \n",
    "           ylabels=['Student {}'.format(i) for i in range(1,5)],\n",
    "           main='Predicted receptive language scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressive Vocabulary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_vocab_dataset = analysis_subset[(analysis_subset.domain=='Expressive Vocabulary')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_vocab_4 = generate_model(expressive_vocab_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with expressive_vocab_4:\n",
    "    \n",
    "    expressive_vocab_4_trace = sample(iterations, tune=tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(expressive_vocab_4_trace, varnames=['Î²'], ylabels=labels, main='Receptive Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(expressive_vocab_4_trace, varnames=[\"predictions\"], rhat=False, \n",
    "           ylabels=['Student {}'.format(i) for i in range(1,5)],\n",
    "           main='Predicted receptive language scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive Vocabulary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_vocab_dataset = analysis_subset[(analysis_subset.domain=='Receptive Vocabulary')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_vocab_4 = generate_model(receptive_vocab_dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with receptive_vocab_4:\n",
    "    \n",
    "    receptive_vocab_4_trace = sample(iterations, tune=tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(receptive_vocab_4_trace, varnames=['Î²'], ylabels=labels, main='Receptive Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestplot(receptive_vocab_4_trace, varnames=[\"predictions\"], rhat=False, \n",
    "           ylabels=['Student {}'.format(i) for i in range(1,5)],\n",
    "           main='Predicted receptive language scores')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
